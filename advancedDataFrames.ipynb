{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86a83091-16e5-47bf-9f69-b4c67496f34b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Merging DataFrames\n",
    "Inthis notebook we're going to address how you can bring multiple dataframe objects together, either by merging them horizontally, or by concatenating them vertically. Before we jump into the code, we need to address a little relational theory and to get some language convetions down. A Venn Diagram is traditionally used to show set membership. For example, the circle on the left is the population of students at a university. The circle on the right is the population of staff at university. And the overlapping regio un this middle are all of those students who are also staff. Maybe these students run tutorials for a course, or grade assignments, or engage in running research experiments. So, this diagram shows two populations whom we nught have data about, but there is overlap between those populations.\n",
    "When it comes to translation this pandas, we can think of the case where we might have these two populations as indices in separate DataFrames, maybe with the label of PersonName. When we want to join the DataFrames together, we have some choices to maje, First what if we want a listo of all the people regardless of whether they're staff or student, and all of the inforamtion we can get of them? In database terminology, this is called a full outer join. And in ser theory, it's called a union. In the Venn diagram, it represents everyone in any circle.\n",
    "FULL OUTER JOIN (UNION) All elements of both sets.\n",
    "It's quite possible though that we only want those people who we hace maximum information for, these people who are both staff and students. Maybe being a staff member and a studen involves getting a tuition waiver, and we want to calculate the cost of this. In database terminology, this is called an inner join. Or in set theory, the intersection.\n",
    "INNER JOIN (INTERSECTION) Only elments are in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45dcb51d-3345-4456-a09a-b11d002dd9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Role\n",
      "Name                 \n",
      "Kelly  Director of HR\n",
      "Sally  Course liasion\n",
      "James          Grader\n",
      "            School\n",
      "Name              \n",
      "James     Business\n",
      "Mike           Law\n",
      "Sally  Engineering\n"
     ]
    }
   ],
   "source": [
    "#Let's to create two dataframes for explore the diferents forms to merging it.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "staff_df = pd.DataFrame([{'Name': 'Kelly', 'Role': 'Director of HR'},\n",
    "                         {'Name': 'Sally', 'Role': 'Course liasion'},\n",
    "                         {'Name': 'James', 'Role': 'Grader'}])\n",
    "staff_df.set_index('Name', inplace = True)\n",
    "\n",
    "student_df = pd.DataFrame([{'Name': 'James', 'School': 'Business'},\n",
    "                           {'Name': 'Mike', 'School': 'Law'},\n",
    "                           {'Name': 'Sally', 'School': 'Engineering'}])\n",
    "\n",
    "student_df.set_index('Name', inplace = True)\n",
    "\n",
    "print(staff_df)\n",
    "print(student_df)\n",
    "# There's some overlap in these DataFrames, in that James and Sally are both students and staff, but Mike and Kelly are not. Importantly, both DataFrames are indexed along the value we want to\n",
    "# merge them on, which is called Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac9fbf7b-4baf-439e-9c85-e34c52ba0d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>School</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>Grader</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kelly</th>\n",
       "      <td>Director of HR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mike</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sally</th>\n",
       "      <td>Course liasion</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Role       School\n",
       "Name                              \n",
       "James          Grader     Business\n",
       "Kelly  Director of HR          NaN\n",
       "Mike              NaN          Law\n",
       "Sally  Course liasion  Engineering"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we want the union of these, we would call merge() passing in the DataFrame on the left and the DataFrame on the right and telling merge that we want it to use an outer join.\n",
    "# We want to use the left and right indices as the joining columns.\n",
    "pd.merge(staff_df, student_df, how = 'outer', left_index = True, right_index = True) # left_index and reight index are for use both indexes to join dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace1ca95-f2a2-46cb-b58c-e5986aca4c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>School</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sally</th>\n",
       "      <td>Course liasion</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>Grader</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Role       School\n",
       "Name                              \n",
       "Sally  Course liasion  Engineering\n",
       "James          Grader     Business"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see in the resulting DataFrame that everyone is listed. And since Mike dos not have a role, and John does not have a school those cells are listed as missing values.\n",
    "# If we wanted to ge the intersection, that is, just those who are a student AND a staff, we could ser the how attribute to inner. Again, we set both left and right indices to be true as the joining cols.\n",
    "pd.merge(staff_df, student_df, how = 'inner', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c08b9eaf-a107-4d5d-84c5-9b30061c4041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>School</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kelly</th>\n",
       "      <td>Director of HR</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sally</th>\n",
       "      <td>Course liasion</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>Grader</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Role       School\n",
       "Name                              \n",
       "Kelly  Director of HR          NaN\n",
       "Sally  Course liasion  Engineering\n",
       "James          Grader     Business"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And we see the resulting DataFrame has only James and Sally in it. Now there are two other common use cases whe merging DataFrames, and both are examples of what we would call set addition. \n",
    "# The first is when we would want to get a list of all staff regardless of wether they were students or not. Buy if ther were students, we would want to get their student details as well. To do this\n",
    "# we would use a left join. It is important to note the order of dataframes in this function: the first dataframe is the left dataframe and the second is the right.\n",
    "pd.merge(staff_df, student_df, how = 'left', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07ca52c6-165e-4e4a-a5d4-a9baee92913e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Role</th>\n",
       "      <th>School</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>Grader</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mike</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sally</th>\n",
       "      <td>Course liasion</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Role       School\n",
       "Name                              \n",
       "James          Grader     Business\n",
       "Mike              NaN          Law\n",
       "Sally  Course liasion  Engineering"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We could probably guess what comes next. We want a list of all of the students and their roles if they were also staff. To do this we would do a right join.\n",
    "pd.merge(staff_df, student_df, how = 'right', left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b461b736-9786-45c5-954e-7d562d4c14fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Role</th>\n",
       "      <th>School</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td>Grader</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mike</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sally</td>\n",
       "      <td>Course liasion</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name            Role       School\n",
       "0  James          Grader     Business\n",
       "1   Mike             NaN          Law\n",
       "2  Sally  Course liasion  Engineering"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also do it another way. The merge method has a couple of other interesting parameters. First, you don't need to use indeces to join on, you can use columns as well. Here's an example.\n",
    "# Here we have a parameter called \"on\", and we can assign a column that both dataframe has the joining column.\n",
    "# First, lets remove our index from both of our dataframes\n",
    "staff_df = staff_df.reset_index()\n",
    "student_df = student_df.reset_index()\n",
    "\n",
    "# Now lets merge using the on parameter\n",
    "pd.merge(staff_df, student_df, how='right', on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b53cc5f8-249d-47bb-8d9a-989915e8ae53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Role</th>\n",
       "      <th>Location_x</th>\n",
       "      <th>School</th>\n",
       "      <th>Location_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kelly</td>\n",
       "      <td>Director of HR</td>\n",
       "      <td>State Street</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sally</td>\n",
       "      <td>Course liasion</td>\n",
       "      <td>Washington Avenue</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>512 Wilson Crescent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James</td>\n",
       "      <td>Grader</td>\n",
       "      <td>Washington Avenue</td>\n",
       "      <td>Business</td>\n",
       "      <td>1024 Billiard Avenue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name            Role         Location_x       School            Location_y\n",
       "0  Kelly  Director of HR       State Street          NaN                   NaN\n",
       "1  Sally  Course liasion  Washington Avenue  Engineering   512 Wilson Crescent\n",
       "2  James          Grader  Washington Avenue     Business  1024 Billiard Avenue"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the \"on\" parameter instead of a the index is how I find myself usign merge() the most. So what happens when we have conflicts between the DataFrames? Let's try take a look by creating new staff \n",
    "# and student DataFrames that have a location information added to them.\n",
    "staff_df = pd.DataFrame([{'Name': 'Kelly', 'Role': 'Director of HR', 'Location': 'State Street'},\n",
    "                         {'Name': 'Sally', 'Role': 'Course liasion', 'Location': 'Washington Avenue'},\n",
    "                         {'Name': 'James', 'Role': 'Grader', 'Location': 'Washington Avenue'}])\n",
    "student_df = pd.DataFrame([{'Name': 'James', 'School': 'Business', 'Location': '1024 Billiard Avenue'},\n",
    "                           {'Name': 'Mike', 'School': 'Law', 'Location': 'Fraternity House #22'},\n",
    "                           {'Name': 'Sally', 'School': 'Engineering', 'Location': '512 Wilson Crescent'}])\n",
    "# In this staff DataFrame, this is an office location where we can find the staff person. And we can see the Director of HR is on Satate Street, while the two srtudents are on Washington Avenue, and\n",
    "# these locations just happen to be right outside my window as I film this. But for the studen DataFrame , the location information is actually their home address.\n",
    "# Ther merge function preserves this informations, but appends and _x or _y to help differentiate betwwen which index went which column of data. The _x is always the left DataFrame information, and\n",
    "# the _y is always the right DataFrame information.\n",
    "# Here, if we want all the staff information regardless of whether they were students or not. But if they were students, we could want to get their student details as well. Then we can do a left join\n",
    "# and on the column of Name\n",
    "pd.merge(staff_df, student_df, how = 'left', on = 'Name')\n",
    "# From the outpout, we can see there are columns locations_x and location_y. Location x refers to the location column in the left dataframe which is staff dataframe and location_y refers to the location\n",
    "#column in the right dataFrame, which is studen dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e5f3b5f-cce7-4a57-99a6-da88950f330f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Role</th>\n",
       "      <th>School</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sally</td>\n",
       "      <td>Brooks</td>\n",
       "      <td>Course liasion</td>\n",
       "      <td>Engineering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First Name Last Name            Role       School\n",
       "0      Sally    Brooks  Course liasion  Engineering"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before we leave merging DataFrames, Let's talk about multi - indexing and mulple columns. In's quite possible that the first name for students and staff might overla but the last name might not. \n",
    "# In his case, we use a list of the multiple columns that should be used to join keys from both dataframes on the on parameter. Recall that the column name (s) assigned to the on parameter needs\n",
    "# to exist in both dataframes.\n",
    "# Here's an example with some new student and staff data\n",
    "staff_df = pd.DataFrame([{'First Name': 'Kelly', 'Last Name': 'Desjardins', \n",
    "                          'Role': 'Director of HR'},\n",
    "                         {'First Name': 'Sally', 'Last Name': 'Brooks', \n",
    "                          'Role': 'Course liasion'},\n",
    "                         {'First Name': 'James', 'Last Name': 'Wilde', \n",
    "                          'Role': 'Grader'}])\n",
    "student_df = pd.DataFrame([{'First Name': 'James', 'Last Name': 'Hammond', \n",
    "                            'School': 'Business'},\n",
    "                           {'First Name': 'Mike', 'Last Name': 'Smith', \n",
    "                            'School': 'Law'},\n",
    "                           {'First Name': 'Sally', 'Last Name': 'Brooks', \n",
    "                            'School': 'Engineering'}])\n",
    "# AS you see here, James Wilde and James Hammond don't match on both keys since they have different last names. So we could expect that an inner join doesn't include these individuals in the output\n",
    "# an only Sally Brooks will be retained\n",
    "pd.merge(staff_df, student_df, how = 'inner', on = ['First Name', 'Last Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d1fbc9-a0f7-44dd-beaf-db2022e807c1",
   "metadata": {},
   "source": [
    "## Python idioms\n",
    "### Pandorable\n",
    "Python programmers will often suggest that there many ways the language can be used to solve a particular problem. But that some more appropriate than others. The best solutions are celebrated as Idiomatic Python and there are lots of great examples of this on StackOverflow and other websites.\n",
    "A sort of sub-language within Python, Pandas has its owm set idioms. We've alluded to some of these already, such as using vectorization whenever possible, and not using iterative loops if you don't need to. Several developers and users within the Panda's community have used the term pandorable for these idioms. I think it's a great term. So, I wanted to share with you a couple of key features of how you can make your code pandorable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a97b7935-b1bb-4816-9c8d-214adf7ac9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "      <th>Estimates Base 2010</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>POPESTIMATE2011</th>\n",
       "      <th>POPESTIMATE2012</th>\n",
       "      <th>...</th>\n",
       "      <th>RDOMESTICMIG2011</th>\n",
       "      <th>RDOMESTICMIG2012</th>\n",
       "      <th>RDOMESTICMIG2013</th>\n",
       "      <th>RDOMESTICMIG2014</th>\n",
       "      <th>RDOMESTICMIG2015</th>\n",
       "      <th>RNETMIG2011</th>\n",
       "      <th>RNETMIG2012</th>\n",
       "      <th>RNETMIG2013</th>\n",
       "      <th>RNETMIG2014</th>\n",
       "      <th>RNETMIG2015</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Alabama</th>\n",
       "      <th>Autauga County</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54571</td>\n",
       "      <td>54571</td>\n",
       "      <td>54660</td>\n",
       "      <td>55253</td>\n",
       "      <td>55175</td>\n",
       "      <td>...</td>\n",
       "      <td>7.242091</td>\n",
       "      <td>-2.915927</td>\n",
       "      <td>-3.012349</td>\n",
       "      <td>2.265971</td>\n",
       "      <td>-2.530799</td>\n",
       "      <td>7.606016</td>\n",
       "      <td>-2.626146</td>\n",
       "      <td>-2.722002</td>\n",
       "      <td>2.592270</td>\n",
       "      <td>-2.187333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baldwin County</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>182265</td>\n",
       "      <td>182265</td>\n",
       "      <td>183193</td>\n",
       "      <td>186659</td>\n",
       "      <td>190396</td>\n",
       "      <td>...</td>\n",
       "      <td>14.832960</td>\n",
       "      <td>17.647293</td>\n",
       "      <td>21.845705</td>\n",
       "      <td>19.243287</td>\n",
       "      <td>17.197872</td>\n",
       "      <td>15.844176</td>\n",
       "      <td>18.559627</td>\n",
       "      <td>22.727626</td>\n",
       "      <td>20.317142</td>\n",
       "      <td>18.293499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barbour County</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>27457</td>\n",
       "      <td>27457</td>\n",
       "      <td>27341</td>\n",
       "      <td>27226</td>\n",
       "      <td>27159</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.728132</td>\n",
       "      <td>-2.500690</td>\n",
       "      <td>-7.056824</td>\n",
       "      <td>-3.904217</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>-4.874741</td>\n",
       "      <td>-2.758113</td>\n",
       "      <td>-7.167664</td>\n",
       "      <td>-3.978583</td>\n",
       "      <td>-10.543299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bibb County</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>22915</td>\n",
       "      <td>22919</td>\n",
       "      <td>22861</td>\n",
       "      <td>22733</td>\n",
       "      <td>22642</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.527043</td>\n",
       "      <td>-5.068871</td>\n",
       "      <td>-6.201001</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>-5.088389</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-5.403729</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>1.107861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blount County</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>57322</td>\n",
       "      <td>57322</td>\n",
       "      <td>57373</td>\n",
       "      <td>57711</td>\n",
       "      <td>57776</td>\n",
       "      <td>...</td>\n",
       "      <td>1.807375</td>\n",
       "      <td>-1.177622</td>\n",
       "      <td>-1.748766</td>\n",
       "      <td>-2.062535</td>\n",
       "      <td>-1.369970</td>\n",
       "      <td>1.859511</td>\n",
       "      <td>-0.848580</td>\n",
       "      <td>-1.402476</td>\n",
       "      <td>-1.577232</td>\n",
       "      <td>-0.884411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Wyoming</th>\n",
       "      <th>Sweetwater County</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>37</td>\n",
       "      <td>43806</td>\n",
       "      <td>43806</td>\n",
       "      <td>43593</td>\n",
       "      <td>44041</td>\n",
       "      <td>45104</td>\n",
       "      <td>...</td>\n",
       "      <td>1.072643</td>\n",
       "      <td>16.243199</td>\n",
       "      <td>-5.339774</td>\n",
       "      <td>-14.252889</td>\n",
       "      <td>-14.248864</td>\n",
       "      <td>1.255221</td>\n",
       "      <td>16.243199</td>\n",
       "      <td>-5.295460</td>\n",
       "      <td>-14.075283</td>\n",
       "      <td>-14.070195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Teton County</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>21294</td>\n",
       "      <td>21294</td>\n",
       "      <td>21297</td>\n",
       "      <td>21482</td>\n",
       "      <td>21697</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.589565</td>\n",
       "      <td>0.972695</td>\n",
       "      <td>19.525929</td>\n",
       "      <td>14.143021</td>\n",
       "      <td>-0.564849</td>\n",
       "      <td>0.654527</td>\n",
       "      <td>2.408578</td>\n",
       "      <td>21.160658</td>\n",
       "      <td>16.308671</td>\n",
       "      <td>1.520747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uinta County</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>41</td>\n",
       "      <td>21118</td>\n",
       "      <td>21118</td>\n",
       "      <td>21102</td>\n",
       "      <td>20912</td>\n",
       "      <td>20989</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.755986</td>\n",
       "      <td>-4.916350</td>\n",
       "      <td>-6.902954</td>\n",
       "      <td>-14.215862</td>\n",
       "      <td>-12.127022</td>\n",
       "      <td>-18.136812</td>\n",
       "      <td>-5.536861</td>\n",
       "      <td>-7.521840</td>\n",
       "      <td>-14.740608</td>\n",
       "      <td>-12.606351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washakie County</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>8533</td>\n",
       "      <td>8533</td>\n",
       "      <td>8545</td>\n",
       "      <td>8469</td>\n",
       "      <td>8443</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.637475</td>\n",
       "      <td>-0.827815</td>\n",
       "      <td>-2.013502</td>\n",
       "      <td>-17.781491</td>\n",
       "      <td>1.682288</td>\n",
       "      <td>-11.990126</td>\n",
       "      <td>-1.182592</td>\n",
       "      <td>-2.250385</td>\n",
       "      <td>-18.020168</td>\n",
       "      <td>1.441961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weston County</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "      <td>7208</td>\n",
       "      <td>7208</td>\n",
       "      <td>7181</td>\n",
       "      <td>7114</td>\n",
       "      <td>7065</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.752361</td>\n",
       "      <td>-8.040059</td>\n",
       "      <td>12.372583</td>\n",
       "      <td>1.533635</td>\n",
       "      <td>6.935294</td>\n",
       "      <td>-12.032179</td>\n",
       "      <td>-8.040059</td>\n",
       "      <td>12.372583</td>\n",
       "      <td>1.533635</td>\n",
       "      <td>6.935294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3142 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           SUMLEV  REGION  DIVISION  STATE  COUNTY  \\\n",
       "STNAME  CTYNAME                                                      \n",
       "Alabama Autauga County         50       3         6      1       1   \n",
       "        Baldwin County         50       3         6      1       3   \n",
       "        Barbour County         50       3         6      1       5   \n",
       "        Bibb County            50       3         6      1       7   \n",
       "        Blount County          50       3         6      1       9   \n",
       "...                           ...     ...       ...    ...     ...   \n",
       "Wyoming Sweetwater County      50       4         8     56      37   \n",
       "        Teton County           50       4         8     56      39   \n",
       "        Uinta County           50       4         8     56      41   \n",
       "        Washakie County        50       4         8     56      43   \n",
       "        Weston County          50       4         8     56      45   \n",
       "\n",
       "                           CENSUS2010POP  Estimates Base 2010  \\\n",
       "STNAME  CTYNAME                                                 \n",
       "Alabama Autauga County             54571                54571   \n",
       "        Baldwin County            182265               182265   \n",
       "        Barbour County             27457                27457   \n",
       "        Bibb County                22915                22919   \n",
       "        Blount County              57322                57322   \n",
       "...                                  ...                  ...   \n",
       "Wyoming Sweetwater County          43806                43806   \n",
       "        Teton County               21294                21294   \n",
       "        Uinta County               21118                21118   \n",
       "        Washakie County             8533                 8533   \n",
       "        Weston County               7208                 7208   \n",
       "\n",
       "                           POPESTIMATE2010  POPESTIMATE2011  POPESTIMATE2012  \\\n",
       "STNAME  CTYNAME                                                                \n",
       "Alabama Autauga County               54660            55253            55175   \n",
       "        Baldwin County              183193           186659           190396   \n",
       "        Barbour County               27341            27226            27159   \n",
       "        Bibb County                  22861            22733            22642   \n",
       "        Blount County                57373            57711            57776   \n",
       "...                                    ...              ...              ...   \n",
       "Wyoming Sweetwater County            43593            44041            45104   \n",
       "        Teton County                 21297            21482            21697   \n",
       "        Uinta County                 21102            20912            20989   \n",
       "        Washakie County               8545             8469             8443   \n",
       "        Weston County                 7181             7114             7065   \n",
       "\n",
       "                           ...  RDOMESTICMIG2011  RDOMESTICMIG2012  \\\n",
       "STNAME  CTYNAME            ...                                       \n",
       "Alabama Autauga County     ...          7.242091         -2.915927   \n",
       "        Baldwin County     ...         14.832960         17.647293   \n",
       "        Barbour County     ...         -4.728132         -2.500690   \n",
       "        Bibb County        ...         -5.527043         -5.068871   \n",
       "        Blount County      ...          1.807375         -1.177622   \n",
       "...                        ...               ...               ...   \n",
       "Wyoming Sweetwater County  ...          1.072643         16.243199   \n",
       "        Teton County       ...         -1.589565          0.972695   \n",
       "        Uinta County       ...        -17.755986         -4.916350   \n",
       "        Washakie County    ...        -11.637475         -0.827815   \n",
       "        Weston County      ...        -11.752361         -8.040059   \n",
       "\n",
       "                           RDOMESTICMIG2013  RDOMESTICMIG2014  \\\n",
       "STNAME  CTYNAME                                                 \n",
       "Alabama Autauga County            -3.012349          2.265971   \n",
       "        Baldwin County            21.845705         19.243287   \n",
       "        Barbour County            -7.056824         -3.904217   \n",
       "        Bibb County               -6.201001         -0.177537   \n",
       "        Blount County             -1.748766         -2.062535   \n",
       "...                                     ...               ...   \n",
       "Wyoming Sweetwater County         -5.339774        -14.252889   \n",
       "        Teton County              19.525929         14.143021   \n",
       "        Uinta County              -6.902954        -14.215862   \n",
       "        Washakie County           -2.013502        -17.781491   \n",
       "        Weston County             12.372583          1.533635   \n",
       "\n",
       "                           RDOMESTICMIG2015  RNETMIG2011  RNETMIG2012  \\\n",
       "STNAME  CTYNAME                                                         \n",
       "Alabama Autauga County            -2.530799     7.606016    -2.626146   \n",
       "        Baldwin County            17.197872    15.844176    18.559627   \n",
       "        Barbour County           -10.543299    -4.874741    -2.758113   \n",
       "        Bibb County                0.177258    -5.088389    -4.363636   \n",
       "        Blount County             -1.369970     1.859511    -0.848580   \n",
       "...                                     ...          ...          ...   \n",
       "Wyoming Sweetwater County        -14.248864     1.255221    16.243199   \n",
       "        Teton County              -0.564849     0.654527     2.408578   \n",
       "        Uinta County             -12.127022   -18.136812    -5.536861   \n",
       "        Washakie County            1.682288   -11.990126    -1.182592   \n",
       "        Weston County              6.935294   -12.032179    -8.040059   \n",
       "\n",
       "                           RNETMIG2013  RNETMIG2014  RNETMIG2015  \n",
       "STNAME  CTYNAME                                                   \n",
       "Alabama Autauga County       -2.722002     2.592270    -2.187333  \n",
       "        Baldwin County       22.727626    20.317142    18.293499  \n",
       "        Barbour County       -7.167664    -3.978583   -10.543299  \n",
       "        Bibb County          -5.403729     0.754533     1.107861  \n",
       "        Blount County        -1.402476    -1.577232    -0.884411  \n",
       "...                                ...          ...          ...  \n",
       "Wyoming Sweetwater County    -5.295460   -14.075283   -14.070195  \n",
       "        Teton County         21.160658    16.308671     1.520747  \n",
       "        Uinta County         -7.521840   -14.740608   -12.606351  \n",
       "        Washakie County      -2.250385   -18.020168     1.441961  \n",
       "        Weston County        12.372583     1.533635     6.935294  \n",
       "\n",
       "[3142 rows x 98 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/census.csv')\n",
    "# The first of the pandas idioms I would like to talk about is called method chaining. The general idea behind method chaining is that every method on an object returns a reference to that object. \n",
    "# The beauty of this is that you can condense many different operations on a DataFrame, for instance, into one line or at least one statement of code. \n",
    "# Here's the pandorable way to write code with method chaining. In this code I'm going to pull out the state and city names as a multiple index, and I'm going to do so only for data which has a\n",
    "# summary level of 50, which in this dataset is county - level data. I'll rename a column too, just to make it a bit more readable.\n",
    "(df.where(df['SUMLEV'] == 50)\n",
    "   .dropna()\n",
    "   .set_index(['STNAME', 'CTYNAME'])\n",
    "   .rename(columns = {'ESTIMATESBASE2010': 'Estimates Base 2010'}))\n",
    "# Lets walk through this.First, we use the where() function on the dataframe and pass in a boolean mask which is only true for those rows where SUMLE is equal to 50. This indicates in our source data\n",
    "# is summarized at the conuty level. With te result of where() function evaluated, we drop missing values. Remember that .where() doesn't drop missing values by default. The we set an index on the\n",
    "# result of that. In this case I've set it to the state name followed by the county name. Finally, I rename a column to mmake it more readable. Note that instead od writing this all on one line,\n",
    "# as I could have done, I bega the statemen with parenthesus, which tell python I'm going to span the statemen over multiple lines for readability.\n",
    "df[df['SUMLEV']==50].set_index(['STNAME','CTYNAME']).rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'}) # this is alternative way, only in one line and use [] operator with boolean mask\n",
    "# instaed of where and dropna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "219c180d-da4c-46d2-a5d0-9df3d5e31e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26023850000001403"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, the key with ony good idiom is to understand when it isn't helping you. In this case, you can actually time both methods and see which on run faster. We can put the approach into a function\n",
    "# and pass the function into the timeit function to count the time the paramet number allows us to choose how many times we want to run the function. Here we will just set it to 10\n",
    "def first_approach():\n",
    "    global df\n",
    "    return (df.where(df['SUMLEV']==50)\n",
    "             .dropna()\n",
    "             .set_index(['STNAME','CTYNAME'])\n",
    "             .rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'}))\n",
    "\n",
    "# Read in our dataset anew\n",
    "df = pd.read_csv('data/census.csv')\n",
    "\n",
    "# And now lets run it\n",
    "timeit.timeit(first_approach, number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "502b403b-cc0d-4aba-b3d8-2d9672f82560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07653289999961999"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's test the second approach. As you may notice, we use our global variable df in the function. However, changing a global variable inside a function will modify the variable even in a global scope and we\n",
    "# do not want that to happen in this case. Therefore, for selecting summary levels of 50 only, I create a new dataframe for those records\n",
    "\n",
    "\n",
    "def second_approach():\n",
    "    global df\n",
    "    return df[df['SUMLEV']==50].set_index(['STNAME','CTYNAME']).rename(columns={'ESTIMATESBASE2010': 'Estimates Base 2010'})\n",
    "\n",
    "# Read in our dataset anew\n",
    "df = pd.read_csv('data/census.csv')\n",
    "\n",
    "# And now lets run it\n",
    "timeit.timeit(second_approach, number=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd810cd1-aca1-4ba8-b163-b71a25e9380f",
   "metadata": {},
   "source": [
    "As you can see, the second approach is much faster!. So, this is a particular example of a classic time readability trade off. You'll see lots of examples on stack overflow and in documentatiorn of people using method chaining in their pandas. And so, I think being able to read and understand the syntax is really worth your time, But keep in mind tha following what appears to be stylistic idioms might have performance issues that you need to consider as well.\n",
    "### Maps\n",
    "Here's another pandas idiom. Python has wonderful function called map, which is sort of basis for functional programming in the language. When you want to use map in Pyhton, you pass it some funciton you want called, and some iterable, like a list, that you want the funtion to be applied to. The results are that the function is called agains each item in the list, and ther's a resulting list of all of the evaluations of that function. \n",
    "Pandas has a similar function called applymap, In applymap, you provide some function which should operate on each cell of DataFrame, and the return set is itself a DataFrame. Now I think applymap is fine, but I actually earely use it. Instead, I find myself often wating to map acroos all of the rows in DataFrame. And pandas has a function that I use heavule ther, called apply. Let' look at example. Let's take a llok at our census DataFrame. In this DataFrame, we have five columns for population estimates with each column corresponding with one year of estimates. It's quite reasonable to want to creat some new columns for minimun or maximun values, and the apply functon is an easy way to do this.\n",
    "First, we need to write a functon chich takes in a particula row of data, finds a minum and maximun values, and returns a new row of data and returns a new row of data. We'll call this function min_max, this is pretty straight forward. We can create some small slice of a row by projecting the population columns. Then use the Numpy min and max functions, and create a new series with label values represent the new values we want to apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dc4bfe9-1950-4660-b0ce-639d18e1709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(row):\n",
    "    data = row[['POPESTIMATE2010',\n",
    "                'POPESTIMATE2011',\n",
    "                'POPESTIMATE2012',\n",
    "                'POPESTIMATE2013',\n",
    "                'POPESTIMATE2014',\n",
    "                'POPESTIMATE2015']]\n",
    "    return pd.Series({'min': np.min(data), 'max': np.max(data)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae7440f1-beda-402a-ae34-0971c79bf2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.67 s ± 289 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "# Then we just need to call apply on the DataFrame. Apply tajes the function and the axis on which to operate as parameters. Now, we have to be a bit careful, we've talked about axis zero being the\n",
    "# rows of the DataFrame in the past. But this parameter is really the parameter of the index to use. So, to apply across all rows, which is applying on all columns, you pass axis equal to columns.\n",
    "df = pd.read_csv('data/census.csv')\n",
    "df.apply(min_max, axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51dc8ca6-042d-4831-844e-efb82f7e9838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19 s ± 93.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "df = pd.read_csv('data/census.csv')\n",
    "df[['POPESTIMATE2010',\n",
    "    'POPESTIMATE2011',\n",
    "    'POPESTIMATE2012',\n",
    "    'POPESTIMATE2013',\n",
    "    'POPESTIMATE2014',\n",
    "    'POPESTIMATE2015']].apply([np.min, np.max], axis = 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a47325-b48c-479e-9630-b746e957f024",
   "metadata": {},
   "source": [
    "Of course there's no need to limit yourself to returning a new series object. If you're doing this as part of data cleaning your likely to find yourself wanting to add to the existing DataFrame. In that case you just take the row values and add in new columns indicating the max an minimun scores. This is a regular part of my workflow when bringing in data and building summary or descriptive sratistics, and is often used heavuly with the merging of DataFrames.\n",
    "Here's an exmaple where we have a revised version of the functon min_max Instead of returning a separate series to display the min and max we add two new columns in the original dataframe to store min and max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6c2f6b2-627d-4d21-8327-8a9496347df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "      <th>ESTIMATESBASE2010</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>...</th>\n",
       "      <th>RDOMESTICMIG2013</th>\n",
       "      <th>RDOMESTICMIG2014</th>\n",
       "      <th>RDOMESTICMIG2015</th>\n",
       "      <th>RNETMIG2011</th>\n",
       "      <th>RNETMIG2012</th>\n",
       "      <th>RNETMIG2013</th>\n",
       "      <th>RNETMIG2014</th>\n",
       "      <th>RNETMIG2015</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4779736</td>\n",
       "      <td>4780127</td>\n",
       "      <td>4785161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381066</td>\n",
       "      <td>0.582002</td>\n",
       "      <td>-0.467369</td>\n",
       "      <td>1.030015</td>\n",
       "      <td>0.826644</td>\n",
       "      <td>1.383282</td>\n",
       "      <td>1.724718</td>\n",
       "      <td>0.712594</td>\n",
       "      <td>4858979</td>\n",
       "      <td>4785161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>54571</td>\n",
       "      <td>54571</td>\n",
       "      <td>54660</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.012349</td>\n",
       "      <td>2.265971</td>\n",
       "      <td>-2.530799</td>\n",
       "      <td>7.606016</td>\n",
       "      <td>-2.626146</td>\n",
       "      <td>-2.722002</td>\n",
       "      <td>2.592270</td>\n",
       "      <td>-2.187333</td>\n",
       "      <td>55347</td>\n",
       "      <td>54660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>182265</td>\n",
       "      <td>182265</td>\n",
       "      <td>183193</td>\n",
       "      <td>...</td>\n",
       "      <td>21.845705</td>\n",
       "      <td>19.243287</td>\n",
       "      <td>17.197872</td>\n",
       "      <td>15.844176</td>\n",
       "      <td>18.559627</td>\n",
       "      <td>22.727626</td>\n",
       "      <td>20.317142</td>\n",
       "      <td>18.293499</td>\n",
       "      <td>203709</td>\n",
       "      <td>183193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>27457</td>\n",
       "      <td>27457</td>\n",
       "      <td>27341</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.056824</td>\n",
       "      <td>-3.904217</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>-4.874741</td>\n",
       "      <td>-2.758113</td>\n",
       "      <td>-7.167664</td>\n",
       "      <td>-3.978583</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>27341</td>\n",
       "      <td>26489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>22915</td>\n",
       "      <td>22919</td>\n",
       "      <td>22861</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.201001</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>-5.088389</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-5.403729</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>1.107861</td>\n",
       "      <td>22861</td>\n",
       "      <td>22512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>37</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Sweetwater County</td>\n",
       "      <td>43806</td>\n",
       "      <td>43806</td>\n",
       "      <td>43593</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.339774</td>\n",
       "      <td>-14.252889</td>\n",
       "      <td>-14.248864</td>\n",
       "      <td>1.255221</td>\n",
       "      <td>16.243199</td>\n",
       "      <td>-5.295460</td>\n",
       "      <td>-14.075283</td>\n",
       "      <td>-14.070195</td>\n",
       "      <td>45162</td>\n",
       "      <td>43593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Teton County</td>\n",
       "      <td>21294</td>\n",
       "      <td>21294</td>\n",
       "      <td>21297</td>\n",
       "      <td>...</td>\n",
       "      <td>19.525929</td>\n",
       "      <td>14.143021</td>\n",
       "      <td>-0.564849</td>\n",
       "      <td>0.654527</td>\n",
       "      <td>2.408578</td>\n",
       "      <td>21.160658</td>\n",
       "      <td>16.308671</td>\n",
       "      <td>1.520747</td>\n",
       "      <td>23125</td>\n",
       "      <td>21297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>41</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Uinta County</td>\n",
       "      <td>21118</td>\n",
       "      <td>21118</td>\n",
       "      <td>21102</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.902954</td>\n",
       "      <td>-14.215862</td>\n",
       "      <td>-12.127022</td>\n",
       "      <td>-18.136812</td>\n",
       "      <td>-5.536861</td>\n",
       "      <td>-7.521840</td>\n",
       "      <td>-14.740608</td>\n",
       "      <td>-12.606351</td>\n",
       "      <td>21102</td>\n",
       "      <td>20822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>43</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Washakie County</td>\n",
       "      <td>8533</td>\n",
       "      <td>8533</td>\n",
       "      <td>8545</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.013502</td>\n",
       "      <td>-17.781491</td>\n",
       "      <td>1.682288</td>\n",
       "      <td>-11.990126</td>\n",
       "      <td>-1.182592</td>\n",
       "      <td>-2.250385</td>\n",
       "      <td>-18.020168</td>\n",
       "      <td>1.441961</td>\n",
       "      <td>8545</td>\n",
       "      <td>8316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>45</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>Weston County</td>\n",
       "      <td>7208</td>\n",
       "      <td>7208</td>\n",
       "      <td>7181</td>\n",
       "      <td>...</td>\n",
       "      <td>12.372583</td>\n",
       "      <td>1.533635</td>\n",
       "      <td>6.935294</td>\n",
       "      <td>-12.032179</td>\n",
       "      <td>-8.040059</td>\n",
       "      <td>12.372583</td>\n",
       "      <td>1.533635</td>\n",
       "      <td>6.935294</td>\n",
       "      <td>7234</td>\n",
       "      <td>7065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3193 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUMLEV  REGION  DIVISION  STATE  COUNTY   STNAME            CTYNAME  \\\n",
       "0         40       3         6      1       0  Alabama            Alabama   \n",
       "1         50       3         6      1       1  Alabama     Autauga County   \n",
       "2         50       3         6      1       3  Alabama     Baldwin County   \n",
       "3         50       3         6      1       5  Alabama     Barbour County   \n",
       "4         50       3         6      1       7  Alabama        Bibb County   \n",
       "...      ...     ...       ...    ...     ...      ...                ...   \n",
       "3188      50       4         8     56      37  Wyoming  Sweetwater County   \n",
       "3189      50       4         8     56      39  Wyoming       Teton County   \n",
       "3190      50       4         8     56      41  Wyoming       Uinta County   \n",
       "3191      50       4         8     56      43  Wyoming    Washakie County   \n",
       "3192      50       4         8     56      45  Wyoming      Weston County   \n",
       "\n",
       "      CENSUS2010POP  ESTIMATESBASE2010  POPESTIMATE2010  ...  \\\n",
       "0           4779736            4780127          4785161  ...   \n",
       "1             54571              54571            54660  ...   \n",
       "2            182265             182265           183193  ...   \n",
       "3             27457              27457            27341  ...   \n",
       "4             22915              22919            22861  ...   \n",
       "...             ...                ...              ...  ...   \n",
       "3188          43806              43806            43593  ...   \n",
       "3189          21294              21294            21297  ...   \n",
       "3190          21118              21118            21102  ...   \n",
       "3191           8533               8533             8545  ...   \n",
       "3192           7208               7208             7181  ...   \n",
       "\n",
       "      RDOMESTICMIG2013  RDOMESTICMIG2014  RDOMESTICMIG2015  RNETMIG2011  \\\n",
       "0             0.381066          0.582002         -0.467369     1.030015   \n",
       "1            -3.012349          2.265971         -2.530799     7.606016   \n",
       "2            21.845705         19.243287         17.197872    15.844176   \n",
       "3            -7.056824         -3.904217        -10.543299    -4.874741   \n",
       "4            -6.201001         -0.177537          0.177258    -5.088389   \n",
       "...                ...               ...               ...          ...   \n",
       "3188         -5.339774        -14.252889        -14.248864     1.255221   \n",
       "3189         19.525929         14.143021         -0.564849     0.654527   \n",
       "3190         -6.902954        -14.215862        -12.127022   -18.136812   \n",
       "3191         -2.013502        -17.781491          1.682288   -11.990126   \n",
       "3192         12.372583          1.533635          6.935294   -12.032179   \n",
       "\n",
       "      RNETMIG2012  RNETMIG2013  RNETMIG2014  RNETMIG2015      max      min  \n",
       "0        0.826644     1.383282     1.724718     0.712594  4858979  4785161  \n",
       "1       -2.626146    -2.722002     2.592270    -2.187333    55347    54660  \n",
       "2       18.559627    22.727626    20.317142    18.293499   203709   183193  \n",
       "3       -2.758113    -7.167664    -3.978583   -10.543299    27341    26489  \n",
       "4       -4.363636    -5.403729     0.754533     1.107861    22861    22512  \n",
       "...           ...          ...          ...          ...      ...      ...  \n",
       "3188    16.243199    -5.295460   -14.075283   -14.070195    45162    43593  \n",
       "3189     2.408578    21.160658    16.308671     1.520747    23125    21297  \n",
       "3190    -5.536861    -7.521840   -14.740608   -12.606351    21102    20822  \n",
       "3191    -1.182592    -2.250385   -18.020168     1.441961     8545     8316  \n",
       "3192    -8.040059    12.372583     1.533635     6.935294     7234     7065  \n",
       "\n",
       "[3193 rows x 102 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def min_max(row):\n",
    "    data = row[['POPESTIMATE2010',\n",
    "                'POPESTIMATE2011',\n",
    "                'POPESTIMATE2012',\n",
    "                'POPESTIMATE2013',\n",
    "                'POPESTIMATE2014',\n",
    "                'POPESTIMATE2015']]\n",
    "    # Create a new entry for max\n",
    "    row['max'] = np.max(data)\n",
    "    # Create a new entry for min\n",
    "    row['min'] = np.min(data)\n",
    "    return row\n",
    "# Now just apply the function across the dataframe\n",
    "df.apply(min_max, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7bf9d478-b0a7-45f0-8c61-4e2857b2776d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4858979\n",
       "1      55347\n",
       "2     203709\n",
       "3      27341\n",
       "4      22861\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply is an extremely importan tool in your toolkit. The reason I introudcen apply is here because you rarely see it used with large function definitions, like we did. Instead, you typically see\n",
    "# it used with lambdas. To get the most of the discussion you'll see online, you're going to nee to know how to at least read lambdas. \n",
    "# Here's you can imagine how you might chain several apply calls with lambdas together toc reat a readable yet succinct data manipulation script. One line example of how youy might calculate the max\n",
    "# of the columns using the apply function.\n",
    "rows = ['POPESTIMATE2010', 'POPESTIMATE2011', 'POPESTIMATE2012', 'POPESTIMATE2013','POPESTIMATE2014', 'POPESTIMATE2015']\n",
    "\n",
    "df.apply(lambda x: np.max(x[rows]), axis = 1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73d9b566-ff50-479f-82db-4efdf9f1320b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "      <th>ESTIMATESBASE2010</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>...</th>\n",
       "      <th>RDOMESTICMIG2012</th>\n",
       "      <th>RDOMESTICMIG2013</th>\n",
       "      <th>RDOMESTICMIG2014</th>\n",
       "      <th>RDOMESTICMIG2015</th>\n",
       "      <th>RNETMIG2011</th>\n",
       "      <th>RNETMIG2012</th>\n",
       "      <th>RNETMIG2013</th>\n",
       "      <th>RNETMIG2014</th>\n",
       "      <th>RNETMIG2015</th>\n",
       "      <th>state_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4779736</td>\n",
       "      <td>4780127</td>\n",
       "      <td>4785161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193196</td>\n",
       "      <td>0.381066</td>\n",
       "      <td>0.582002</td>\n",
       "      <td>-0.467369</td>\n",
       "      <td>1.030015</td>\n",
       "      <td>0.826644</td>\n",
       "      <td>1.383282</td>\n",
       "      <td>1.724718</td>\n",
       "      <td>0.712594</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>54571</td>\n",
       "      <td>54571</td>\n",
       "      <td>54660</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.915927</td>\n",
       "      <td>-3.012349</td>\n",
       "      <td>2.265971</td>\n",
       "      <td>-2.530799</td>\n",
       "      <td>7.606016</td>\n",
       "      <td>-2.626146</td>\n",
       "      <td>-2.722002</td>\n",
       "      <td>2.592270</td>\n",
       "      <td>-2.187333</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>182265</td>\n",
       "      <td>182265</td>\n",
       "      <td>183193</td>\n",
       "      <td>...</td>\n",
       "      <td>17.647293</td>\n",
       "      <td>21.845705</td>\n",
       "      <td>19.243287</td>\n",
       "      <td>17.197872</td>\n",
       "      <td>15.844176</td>\n",
       "      <td>18.559627</td>\n",
       "      <td>22.727626</td>\n",
       "      <td>20.317142</td>\n",
       "      <td>18.293499</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>27457</td>\n",
       "      <td>27457</td>\n",
       "      <td>27341</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.500690</td>\n",
       "      <td>-7.056824</td>\n",
       "      <td>-3.904217</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>-4.874741</td>\n",
       "      <td>-2.758113</td>\n",
       "      <td>-7.167664</td>\n",
       "      <td>-3.978583</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>22915</td>\n",
       "      <td>22919</td>\n",
       "      <td>22861</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.068871</td>\n",
       "      <td>-6.201001</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>-5.088389</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-5.403729</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>1.107861</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUMLEV  REGION  DIVISION  STATE  COUNTY   STNAME         CTYNAME  \\\n",
       "0      40       3         6      1       0  Alabama         Alabama   \n",
       "1      50       3         6      1       1  Alabama  Autauga County   \n",
       "2      50       3         6      1       3  Alabama  Baldwin County   \n",
       "3      50       3         6      1       5  Alabama  Barbour County   \n",
       "4      50       3         6      1       7  Alabama     Bibb County   \n",
       "\n",
       "   CENSUS2010POP  ESTIMATESBASE2010  POPESTIMATE2010  ...  RDOMESTICMIG2012  \\\n",
       "0        4779736            4780127          4785161  ...         -0.193196   \n",
       "1          54571              54571            54660  ...         -2.915927   \n",
       "2         182265             182265           183193  ...         17.647293   \n",
       "3          27457              27457            27341  ...         -2.500690   \n",
       "4          22915              22919            22861  ...         -5.068871   \n",
       "\n",
       "   RDOMESTICMIG2013  RDOMESTICMIG2014  RDOMESTICMIG2015  RNETMIG2011  \\\n",
       "0          0.381066          0.582002         -0.467369     1.030015   \n",
       "1         -3.012349          2.265971         -2.530799     7.606016   \n",
       "2         21.845705         19.243287         17.197872    15.844176   \n",
       "3         -7.056824         -3.904217        -10.543299    -4.874741   \n",
       "4         -6.201001         -0.177537          0.177258    -5.088389   \n",
       "\n",
       "   RNETMIG2012  RNETMIG2013  RNETMIG2014  RNETMIG2015  state_region  \n",
       "0     0.826644     1.383282     1.724718     0.712594         South  \n",
       "1    -2.626146    -2.722002     2.592270    -2.187333         South  \n",
       "2    18.559627    22.727626    20.317142    18.293499         South  \n",
       "3    -2.758113    -7.167664    -3.978583   -10.543299         South  \n",
       "4    -4.363636    -5.403729     0.754533     1.107861         South  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The beauty of the apply function is that it allows flexibility in doing whatever manipulating that you desire, as the funciton you pass into apply can be any customized however you want.\n",
    "# Let's say we want to divide the states into four categories: Northeast, Midwest, South, and West We can write a customized function that returns the region based on the state regions information is\n",
    "# obtained from Wikipedia\n",
    "def get_state_region(x):\n",
    "    northeast = ['Connecticut', 'Maine', 'Massachusetts', 'New Hampshire', \n",
    "                 'Rhode Island','Vermont','New York','New Jersey','Pennsylvania']\n",
    "    midwest = ['Illinois','Indiana','Michigan','Ohio','Wisconsin','Iowa',\n",
    "               'Kansas','Minnesota','Missouri','Nebraska','North Dakota',\n",
    "               'South Dakota']\n",
    "    south = ['Delaware','Florida','Georgia','Maryland','North Carolina',\n",
    "             'South Carolina','Virginia','District of Columbia','West Virginia',\n",
    "             'Alabama','Kentucky','Mississippi','Tennessee','Arkansas',\n",
    "             'Louisiana','Oklahoma','Texas']\n",
    "    west = ['Arizona','Colorado','Idaho','Montana','Nevada','New Mexico','Utah',\n",
    "            'Wyoming','Alaska','California','Hawaii','Oregon','Washington']\n",
    "    \n",
    "    if x in northeast:\n",
    "        return \"Northeast\"\n",
    "    elif x in midwest:\n",
    "        return \"Midwest\"\n",
    "    elif x in south:\n",
    "        return \"South\"\n",
    "    else:\n",
    "        return \"West\"\n",
    "\n",
    "# Now we have the customized function, Let's say we want to creat a new column called Region, chich shows the state's region, we can use the customized function and the apply function to do so. \n",
    "# The customized function is supposed to word on the state name column STNAME. So we will set the apply funtion on the state name column and pass the costumizard function on the state name column\n",
    "# and pass the customized function into the apply function\n",
    "df['state_region'] = df['STNAME'].apply(lambda x: get_state_region(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d9fe7-d8ef-490c-8a4a-86c388fbad79",
   "metadata": {},
   "source": [
    "## Group by\n",
    "Sometimes we want to select data based on groups and understand aggregated data on a group level. We have seen that even though Pandas allows us to iterate over every row in a dataFrame, it is generally very slow to do so. Fortunately Pandas has groupby() function to speed up such task. The idea behind the groupby() function is that it takes some dataframe, splits it into chunks based on some key values, applies computation on those chuncks, then combines the results back together into another dataframe. In pandas this is refered to as the split-apply-combine pattern.\n",
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf0787a9-5eab-4228-80b1-1515c55ad1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>REGION</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>CENSUS2010POP</th>\n",
       "      <th>ESTIMATESBASE2010</th>\n",
       "      <th>POPESTIMATE2010</th>\n",
       "      <th>...</th>\n",
       "      <th>RDOMESTICMIG2011</th>\n",
       "      <th>RDOMESTICMIG2012</th>\n",
       "      <th>RDOMESTICMIG2013</th>\n",
       "      <th>RDOMESTICMIG2014</th>\n",
       "      <th>RDOMESTICMIG2015</th>\n",
       "      <th>RNETMIG2011</th>\n",
       "      <th>RNETMIG2012</th>\n",
       "      <th>RNETMIG2013</th>\n",
       "      <th>RNETMIG2014</th>\n",
       "      <th>RNETMIG2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>54571</td>\n",
       "      <td>54571</td>\n",
       "      <td>54660</td>\n",
       "      <td>...</td>\n",
       "      <td>7.242091</td>\n",
       "      <td>-2.915927</td>\n",
       "      <td>-3.012349</td>\n",
       "      <td>2.265971</td>\n",
       "      <td>-2.530799</td>\n",
       "      <td>7.606016</td>\n",
       "      <td>-2.626146</td>\n",
       "      <td>-2.722002</td>\n",
       "      <td>2.592270</td>\n",
       "      <td>-2.187333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Baldwin County</td>\n",
       "      <td>182265</td>\n",
       "      <td>182265</td>\n",
       "      <td>183193</td>\n",
       "      <td>...</td>\n",
       "      <td>14.832960</td>\n",
       "      <td>17.647293</td>\n",
       "      <td>21.845705</td>\n",
       "      <td>19.243287</td>\n",
       "      <td>17.197872</td>\n",
       "      <td>15.844176</td>\n",
       "      <td>18.559627</td>\n",
       "      <td>22.727626</td>\n",
       "      <td>20.317142</td>\n",
       "      <td>18.293499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Barbour County</td>\n",
       "      <td>27457</td>\n",
       "      <td>27457</td>\n",
       "      <td>27341</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.728132</td>\n",
       "      <td>-2.500690</td>\n",
       "      <td>-7.056824</td>\n",
       "      <td>-3.904217</td>\n",
       "      <td>-10.543299</td>\n",
       "      <td>-4.874741</td>\n",
       "      <td>-2.758113</td>\n",
       "      <td>-7.167664</td>\n",
       "      <td>-3.978583</td>\n",
       "      <td>-10.543299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Bibb County</td>\n",
       "      <td>22915</td>\n",
       "      <td>22919</td>\n",
       "      <td>22861</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.527043</td>\n",
       "      <td>-5.068871</td>\n",
       "      <td>-6.201001</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.177258</td>\n",
       "      <td>-5.088389</td>\n",
       "      <td>-4.363636</td>\n",
       "      <td>-5.403729</td>\n",
       "      <td>0.754533</td>\n",
       "      <td>1.107861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Blount County</td>\n",
       "      <td>57322</td>\n",
       "      <td>57322</td>\n",
       "      <td>57373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.807375</td>\n",
       "      <td>-1.177622</td>\n",
       "      <td>-1.748766</td>\n",
       "      <td>-2.062535</td>\n",
       "      <td>-1.369970</td>\n",
       "      <td>1.859511</td>\n",
       "      <td>-0.848580</td>\n",
       "      <td>-1.402476</td>\n",
       "      <td>-1.577232</td>\n",
       "      <td>-0.884411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUMLEV  REGION  DIVISION  STATE  COUNTY   STNAME         CTYNAME  \\\n",
       "1      50       3         6      1       1  Alabama  Autauga County   \n",
       "2      50       3         6      1       3  Alabama  Baldwin County   \n",
       "3      50       3         6      1       5  Alabama  Barbour County   \n",
       "4      50       3         6      1       7  Alabama     Bibb County   \n",
       "5      50       3         6      1       9  Alabama   Blount County   \n",
       "\n",
       "   CENSUS2010POP  ESTIMATESBASE2010  POPESTIMATE2010  ...  RDOMESTICMIG2011  \\\n",
       "1          54571              54571            54660  ...          7.242091   \n",
       "2         182265             182265           183193  ...         14.832960   \n",
       "3          27457              27457            27341  ...         -4.728132   \n",
       "4          22915              22919            22861  ...         -5.527043   \n",
       "5          57322              57322            57373  ...          1.807375   \n",
       "\n",
       "   RDOMESTICMIG2012  RDOMESTICMIG2013  RDOMESTICMIG2014  RDOMESTICMIG2015  \\\n",
       "1         -2.915927         -3.012349          2.265971         -2.530799   \n",
       "2         17.647293         21.845705         19.243287         17.197872   \n",
       "3         -2.500690         -7.056824         -3.904217        -10.543299   \n",
       "4         -5.068871         -6.201001         -0.177537          0.177258   \n",
       "5         -1.177622         -1.748766         -2.062535         -1.369970   \n",
       "\n",
       "   RNETMIG2011  RNETMIG2012  RNETMIG2013  RNETMIG2014  RNETMIG2015  \n",
       "1     7.606016    -2.626146    -2.722002     2.592270    -2.187333  \n",
       "2    15.844176    18.559627    22.727626    20.317142    18.293499  \n",
       "3    -4.874741    -2.758113    -7.167664    -3.978583   -10.543299  \n",
       "4    -5.088389    -4.363636    -5.403729     0.754533     1.107861  \n",
       "5     1.859511    -0.848580    -1.402476    -1.577232    -0.884411  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/census.csv')\n",
    "# And exclude state level summarizations, which have sum level value of 40\n",
    "df = df[df['SUMLEV']==50]\n",
    "df.head()\n",
    "# In the first example for groupby() I want to use the census date. Let's get list of the unique states, then we can interate over all the states and for each state we reduce the dataframe and\n",
    "# calculate the average. Let's run such task for 3 items and time it. For this we'll use cell magic function %%timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "12fdfde1-4f6f-4654-8089-7e1596568533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.6 ms ± 3.33 ms per loop (mean ± std. dev. of 7 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3\n",
    "\n",
    "for state in df['STNAME']. unique():\n",
    "    avg = np.average(df[df['STNAME'] == state]['CENSUS2010POP'])\n",
    "    #print(\"Counties in state {} have an average population of {}\".format(state, str(avg)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "40701710-f0ce-41f1-a1ee-6854a453052c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.77 ms ± 681 µs per loop (mean ± std. dev. of 7 runs, 3 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 3\n",
    "# You will notice there are two values we set here. groupby() returns a tuple, where the first value is the value of the key were tryung to group by, in this case a specific state name, and the\n",
    "# second one is projected dataframe that was found for that group\n",
    "for group, frame  in df.groupby('STNAME'):\n",
    "    avg = np.average(frame['CENSUS2010POP'])\n",
    "    #print(\"Counties in state {} have an average population of {}\".format(state, str(avg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3fe06d15-9749-4c81-a0e0-dd38917145c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1177 records in group 0 for processing.\n",
      "There are 1134 records in group 1 for processing.\n",
      "There are 831 records in group 2 for processing.\n"
     ]
    }
   ],
   "source": [
    "# Wow, what huge difference in speed. An improve by roughly by two factors!. Now, 99% of the time, you'll use group by on one or more columns. But you can also provide a function to group by and use\n",
    "# that to segment your data. This is a bit of a fabricated example but lets sat that you have a big batch job with lots of processing and you want to work only a third or so of the states at given\n",
    "# time. We could create some function which returns a number between zero and two based on the first character of the state name. Then we can tell group bu to use this function to split up or data\n",
    "# frame to be the column that you want to group by first.\n",
    "# We'll create some new function called set_batch_number and if the first letter of the parameter is a capital M we'll return a 0. If it's a capital Q we'll return a 1 and otherwise we'll return a 2.\n",
    "# Then we'll pass this funtion to the dataframe.\n",
    "df.set_index('STNAME', inplace = True)\n",
    "\n",
    "def set_batch_number(item):\n",
    "    if item[0] < 'M':\n",
    "        return 0\n",
    "    if item[0] < 'Q':\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "for group, frame in df.groupby(set_batch_number):\n",
    "    print('There are ' + str(len(frame)) + ' records in group ' + str(group) + ' for processing.')\n",
    "\n",
    "# Notice that this time I didn't pass in a column name to groupby(). Instead, I set the index of the dataframe to be STNAME, and if no column indentifier is passed groupby() will automatically use\n",
    "# the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d728e1a5-d419-4c3c-8c9e-d94de4c4f2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>space</th>\n",
       "      <th>description</th>\n",
       "      <th>experiences_offered</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>requires_license</th>\n",
       "      <th>license</th>\n",
       "      <th>jurisdiction_names</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12147973</td>\n",
       "      <td>https://www.airbnb.com/rooms/12147973</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Sunny Bungalow in the City</td>\n",
       "      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n",
       "      <td>The house has an open and cozy feel at the sam...</td>\n",
       "      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n",
       "      <td>none</td>\n",
       "      <td>Roslindale is quiet, convenient and friendly. ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3075044</td>\n",
       "      <td>https://www.airbnb.com/rooms/3075044</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Charming room in pet friendly apt</td>\n",
       "      <td>Charming and quiet room in a second floor 1910...</td>\n",
       "      <td>Small but cozy and quite room with a full size...</td>\n",
       "      <td>Charming and quiet room in a second floor 1910...</td>\n",
       "      <td>none</td>\n",
       "      <td>The room is in Roslindale, a diverse and prima...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6976</td>\n",
       "      <td>https://www.airbnb.com/rooms/6976</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Mexican Folk Art Haven in Boston</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>none</td>\n",
       "      <td>The LOCATION: Roslindale is a safe and diverse...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1436513</td>\n",
       "      <td>https://www.airbnb.com/rooms/1436513</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Spacious Sunny Bedroom Suite in Historic Home</td>\n",
       "      <td>Come experience the comforts of home away from...</td>\n",
       "      <td>Most places you find in Boston are small howev...</td>\n",
       "      <td>Come experience the comforts of home away from...</td>\n",
       "      <td>none</td>\n",
       "      <td>Roslindale is a lovely little neighborhood loc...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>moderate</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7651065</td>\n",
       "      <td>https://www.airbnb.com/rooms/7651065</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Come Home to Boston</td>\n",
       "      <td>My comfy, clean and relaxing home is one block...</td>\n",
       "      <td>Clean, attractive, private room, one block fro...</td>\n",
       "      <td>My comfy, clean and relaxing home is one block...</td>\n",
       "      <td>none</td>\n",
       "      <td>I love the proximity to downtown, the neighbor...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>flexible</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                            listing_url       scrape_id  \\\n",
       "0  12147973  https://www.airbnb.com/rooms/12147973  20160906204935   \n",
       "1   3075044   https://www.airbnb.com/rooms/3075044  20160906204935   \n",
       "2      6976      https://www.airbnb.com/rooms/6976  20160906204935   \n",
       "3   1436513   https://www.airbnb.com/rooms/1436513  20160906204935   \n",
       "4   7651065   https://www.airbnb.com/rooms/7651065  20160906204935   \n",
       "\n",
       "  last_scraped                                           name  \\\n",
       "0   2016-09-07                     Sunny Bungalow in the City   \n",
       "1   2016-09-07              Charming room in pet friendly apt   \n",
       "2   2016-09-07               Mexican Folk Art Haven in Boston   \n",
       "3   2016-09-07  Spacious Sunny Bedroom Suite in Historic Home   \n",
       "4   2016-09-07                            Come Home to Boston   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Cozy, sunny, family home.  Master bedroom high...   \n",
       "1  Charming and quiet room in a second floor 1910...   \n",
       "2  Come stay with a friendly, middle-aged guy in ...   \n",
       "3  Come experience the comforts of home away from...   \n",
       "4  My comfy, clean and relaxing home is one block...   \n",
       "\n",
       "                                               space  \\\n",
       "0  The house has an open and cozy feel at the sam...   \n",
       "1  Small but cozy and quite room with a full size...   \n",
       "2  Come stay with a friendly, middle-aged guy in ...   \n",
       "3  Most places you find in Boston are small howev...   \n",
       "4  Clean, attractive, private room, one block fro...   \n",
       "\n",
       "                                         description experiences_offered  \\\n",
       "0  Cozy, sunny, family home.  Master bedroom high...                none   \n",
       "1  Charming and quiet room in a second floor 1910...                none   \n",
       "2  Come stay with a friendly, middle-aged guy in ...                none   \n",
       "3  Come experience the comforts of home away from...                none   \n",
       "4  My comfy, clean and relaxing home is one block...                none   \n",
       "\n",
       "                               neighborhood_overview  ... review_scores_value  \\\n",
       "0  Roslindale is quiet, convenient and friendly. ...  ...                 NaN   \n",
       "1  The room is in Roslindale, a diverse and prima...  ...                 9.0   \n",
       "2  The LOCATION: Roslindale is a safe and diverse...  ...                10.0   \n",
       "3  Roslindale is a lovely little neighborhood loc...  ...                10.0   \n",
       "4  I love the proximity to downtown, the neighbor...  ...                10.0   \n",
       "\n",
       "  requires_license license jurisdiction_names instant_bookable  \\\n",
       "0                f     NaN                NaN                f   \n",
       "1                f     NaN                NaN                t   \n",
       "2                f     NaN                NaN                f   \n",
       "3                f     NaN                NaN                f   \n",
       "4                f     NaN                NaN                f   \n",
       "\n",
       "  cancellation_policy require_guest_profile_picture  \\\n",
       "0            moderate                             f   \n",
       "1            moderate                             f   \n",
       "2            moderate                             t   \n",
       "3            moderate                             f   \n",
       "4            flexible                             f   \n",
       "\n",
       "  require_guest_phone_verification calculated_host_listings_count  \\\n",
       "0                                f                              1   \n",
       "1                                f                              1   \n",
       "2                                f                              1   \n",
       "3                                f                              1   \n",
       "4                                f                              1   \n",
       "\n",
       "   reviews_per_month  \n",
       "0                NaN  \n",
       "1               1.30  \n",
       "2               0.47  \n",
       "3               1.00  \n",
       "4               2.25  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take one more look at an example of how we might group data. In this example, I want to use a dataset # of housing from airbnb. In this dataset there are two columns of interest, \n",
    "# one is the cancellation_policy and the other is the review_scores_value.\n",
    "df=pd.read_csv(\"data/listings.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e805846c-391a-4ea4-8375-1bad378d0a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('flexible', 2.0)\n",
      "('flexible', 4.0)\n",
      "('flexible', 5.0)\n",
      "('flexible', 6.0)\n",
      "('flexible', 7.0)\n",
      "('flexible', 8.0)\n",
      "('flexible', 9.0)\n",
      "('flexible', 10.0)\n",
      "('moderate', 2.0)\n",
      "('moderate', 4.0)\n",
      "('moderate', 6.0)\n",
      "('moderate', 7.0)\n",
      "('moderate', 8.0)\n",
      "('moderate', 9.0)\n",
      "('moderate', 10.0)\n",
      "('strict', 2.0)\n",
      "('strict', 3.0)\n",
      "('strict', 4.0)\n",
      "('strict', 5.0)\n",
      "('strict', 6.0)\n",
      "('strict', 7.0)\n",
      "('strict', 8.0)\n",
      "('strict', 9.0)\n",
      "('strict', 10.0)\n",
      "('super_strict_30', 6.0)\n",
      "('super_strict_30', 7.0)\n",
      "('super_strict_30', 8.0)\n",
      "('super_strict_30', 9.0)\n",
      "('super_strict_30', 10.0)\n"
     ]
    }
   ],
   "source": [
    "#df.set_index([\"cancellation_policy\",\"review_scores_value\"], inplace = True)\n",
    "for group, frame in df.groupby(level = (0,1)): # We need to pass the leves which we are interested in group by\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb7cd7c8-e796-4613-bb0f-5c58f34998c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('flexible', '10.0')\n",
      "('flexible', 'not 10.0')\n",
      "('moderate', '10.0')\n",
      "('moderate', 'not 10.0')\n",
      "('strict', '10.0')\n",
      "('strict', 'not 10.0')\n",
      "('super_strict_30', '10.0')\n",
      "('super_strict_30', 'not 10.0')\n"
     ]
    }
   ],
   "source": [
    "# This seems to work ok. But what if we wanted to group by the cancelation policy and review scores, but separate out all the 10's from those under ten? In this case, we could use a function \n",
    "# to manage the groupings\n",
    "\n",
    "def grouping_fun(item):\n",
    "    # Check the \"review_scores_value\" portion of the index. item is in the format of cancellation_policy,review_scores_value\n",
    "    if item[1] == 10.0:\n",
    "        return (item[0],\"10.0\")\n",
    "    else:\n",
    "        return (item[0],\"not 10.0\")\n",
    "\n",
    "for group, frame in df.groupby(by=grouping_fun):\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabbbd7-3f1e-4a47-ae9a-a6f30a981421",
   "metadata": {},
   "source": [
    "## Applying\n",
    "To this point we have applied very simple processing to our data after splitting, really just outputting some print statements to demostrate how the splitting works. The pandas developers have three broad categories of data processing to happen during the apply step: Aggregation of group data, transformation of gruoup data, and filtration of group data\n",
    "### Aggregation\n",
    "The most straingh forward apply step is the aggregation of data, and uses the method agg() on the groupby object. Thus far we have onlu iterated through the groupby object, unpacking in into a label (the group name) and a dataframe. but with agg we can pass in a dictionary of the columns we are interested in aggregating along with the function we are looking to apply to aggregate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e4fb26b0-124b-4c55-9d96-404d37cc864b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">review_scores_value</th>\n",
       "      <th>reviews_per_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>nanmean</th>\n",
       "      <th>nanstd</th>\n",
       "      <th>nanmean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flexible</th>\n",
       "      <td>9.237421</td>\n",
       "      <td>1.096271</td>\n",
       "      <td>1.829210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moderate</th>\n",
       "      <td>9.307398</td>\n",
       "      <td>0.859859</td>\n",
       "      <td>2.391922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict</th>\n",
       "      <td>9.081441</td>\n",
       "      <td>1.040531</td>\n",
       "      <td>1.873467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>super_strict_30</th>\n",
       "      <td>8.537313</td>\n",
       "      <td>0.840785</td>\n",
       "      <td>0.340143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    review_scores_value           reviews_per_month\n",
       "                                nanmean    nanstd           nanmean\n",
       "cancellation_policy                                                \n",
       "flexible                       9.237421  1.096271          1.829210\n",
       "moderate                       9.307398  0.859859          2.391922\n",
       "strict                         9.081441  1.040531          1.873467\n",
       "super_strict_30                8.537313  0.840785          0.340143"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.reset_index(inplace = True)\n",
    "#Now let's group by the cancellation policy and find the average review_scores_value by group\n",
    "df.groupby('cancellation_policy').agg({'review_scores_value': np.nanmean}) # Uses nanmean for work with nan values\n",
    "# We can just extend this dictionary to aggregate by multiple functions or multiple columns.\n",
    "df.groupby(\"cancellation_policy\").agg({\"review_scores_value\":(np.nanmean,np.nanstd), \"reviews_per_month\":np.nanmean})\n",
    "# Take a moment to make sure you understand the previous cell, since it's somewaht complex. First we're doing a group by on the dataframe object by the column \"cancellation_policy\". This creates a \n",
    "# new GroupBy object. Then we are invoking the agg() function on that object. The agg function is going to apply one or more functions we specify to the group dataframes and return a single row per\n",
    "# dataframe/group. When we called this function we sent it two dictionary entries, each with the key indicating which column we wanted functions applied to. For this first column we actually supplied\n",
    "# a tuple of two functions. Note that these are not function invocations, like np.nanmean(), or function names, like \"nanmean\" they are references to functions which will return single values.\n",
    "# The groupby object will recognize the tuple and call each function in order on the same column. The results willbe in a heirarchical index, bu since they are columns they don't show as index per se\n",
    "# Then we indcated another column and a single function we wanted to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fec7260-d524-4122-b533-3a0400607ffd",
   "metadata": {},
   "source": [
    "### transformation \n",
    "Transformation is different from aggreation. Where agg() returns a single value per column, so one row per group, transform() returns an object that is the same size as the group. Essentially, it broadcasts the function you supply over the grouped dataframe, returning a new dataframe This makes combinign data later easy.\n",
    "For instance, suppose we want to include the averga rating values in a given group by cancellation policity, but preserve the dataframe shape so that we could generate a difference between an individual obseration an the sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e6d1ce47-418a-4a7a-91fa-f0455e762c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_scores_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.237421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_scores_value\n",
       "0             9.307398\n",
       "1             9.307398\n",
       "2             9.307398\n",
       "3             9.307398\n",
       "4             9.237421"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, lets define just some subset of columns we are interested in\n",
    "cols = ['cancellation_policy', 'review_scores_value']\n",
    "# now let's transform it, I'll store this in its own dataframe\n",
    "transform_df = df[cols].groupby('cancellation_policy').transform(np.nanmean)\n",
    "transform_df.head() # Return a new dataframe with same size as original group, it make easy other operations. agg only return one element for column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8d8b8942-98f4-49b2-8869-04c6c644ca93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>requires_license</th>\n",
       "      <th>license</th>\n",
       "      <th>jurisdiction_names</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>mean_review_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12147973</td>\n",
       "      <td>https://www.airbnb.com/rooms/12147973</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Sunny Bungalow in the City</td>\n",
       "      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>moderate</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3075044</td>\n",
       "      <td>https://www.airbnb.com/rooms/3075044</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Charming room in pet friendly apt</td>\n",
       "      <td>Charming and quiet room in a second floor 1910...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30</td>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6976</td>\n",
       "      <td>https://www.airbnb.com/rooms/6976</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Mexican Folk Art Haven in Boston</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1436513</td>\n",
       "      <td>https://www.airbnb.com/rooms/1436513</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Spacious Sunny Bedroom Suite in Historic Home</td>\n",
       "      <td>Come experience the comforts of home away from...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>flexible</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7651065</td>\n",
       "      <td>https://www.airbnb.com/rooms/7651065</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Come Home to Boston</td>\n",
       "      <td>My comfy, clean and relaxing home is one block...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>9.237421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index cancellation_policy  review_scores_value        id  \\\n",
       "0        0      0            moderate                  NaN  12147973   \n",
       "1        1      1            moderate                  9.0   3075044   \n",
       "2        2      2            moderate                 10.0      6976   \n",
       "3        3      3            moderate                 10.0   1436513   \n",
       "4        4      4            flexible                 10.0   7651065   \n",
       "\n",
       "                             listing_url       scrape_id last_scraped  \\\n",
       "0  https://www.airbnb.com/rooms/12147973  20160906204935   2016-09-07   \n",
       "1   https://www.airbnb.com/rooms/3075044  20160906204935   2016-09-07   \n",
       "2      https://www.airbnb.com/rooms/6976  20160906204935   2016-09-07   \n",
       "3   https://www.airbnb.com/rooms/1436513  20160906204935   2016-09-07   \n",
       "4   https://www.airbnb.com/rooms/7651065  20160906204935   2016-09-07   \n",
       "\n",
       "                                            name  \\\n",
       "0                     Sunny Bungalow in the City   \n",
       "1              Charming room in pet friendly apt   \n",
       "2               Mexican Folk Art Haven in Boston   \n",
       "3  Spacious Sunny Bedroom Suite in Historic Home   \n",
       "4                            Come Home to Boston   \n",
       "\n",
       "                                             summary  ...  \\\n",
       "0  Cozy, sunny, family home.  Master bedroom high...  ...   \n",
       "1  Charming and quiet room in a second floor 1910...  ...   \n",
       "2  Come stay with a friendly, middle-aged guy in ...  ...   \n",
       "3  Come experience the comforts of home away from...  ...   \n",
       "4  My comfy, clean and relaxing home is one block...  ...   \n",
       "\n",
       "  review_scores_location requires_license license jurisdiction_names  \\\n",
       "0                    NaN                f     NaN                NaN   \n",
       "1                    9.0                f     NaN                NaN   \n",
       "2                    9.0                f     NaN                NaN   \n",
       "3                   10.0                f     NaN                NaN   \n",
       "4                    9.0                f     NaN                NaN   \n",
       "\n",
       "  instant_bookable require_guest_profile_picture  \\\n",
       "0                f                             f   \n",
       "1                t                             f   \n",
       "2                f                             t   \n",
       "3                f                             f   \n",
       "4                f                             f   \n",
       "\n",
       "  require_guest_phone_verification calculated_host_listings_count  \\\n",
       "0                                f                              1   \n",
       "1                                f                              1   \n",
       "2                                f                              1   \n",
       "3                                f                              1   \n",
       "4                                f                              1   \n",
       "\n",
       "  reviews_per_month mean_review_scores  \n",
       "0               NaN           9.307398  \n",
       "1              1.30           9.307398  \n",
       "2              0.47           9.307398  \n",
       "3              1.00           9.307398  \n",
       "4              2.25           9.237421  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So we can see that the index here is actually the same as the original dataframe. So lets just join this in. Before we do that, lets rename the column in the transformed version\n",
    "transform_df.rename({'review_scores_value':'mean_review_scores'}, axis='columns', inplace=True)\n",
    "df=df.merge(transform_df, left_index=True, right_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fb59d2-1617-4c4c-9c54-8eebad73b226",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "The group by object has build in support for filtering groups as well. It's often that you'll want to group by some feature, then some transformation to the groups, the drop certain groups as part of your cleaning reoutines. the filter() function takes in a function chich it applies to each group dataframe and returns either a True or a Flase, depending upon whether that group should be inclued in the results. For instance, if we only want those groups which have a mean rating above 9 inclued in our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ea9df862-2773-4cc1-bf19-9c65023e9bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>summary</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>requires_license</th>\n",
       "      <th>license</th>\n",
       "      <th>jurisdiction_names</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>require_guest_profile_picture</th>\n",
       "      <th>require_guest_phone_verification</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>mean_review_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12147973</td>\n",
       "      <td>https://www.airbnb.com/rooms/12147973</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Sunny Bungalow in the City</td>\n",
       "      <td>Cozy, sunny, family home.  Master bedroom high...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>moderate</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3075044</td>\n",
       "      <td>https://www.airbnb.com/rooms/3075044</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Charming room in pet friendly apt</td>\n",
       "      <td>Charming and quiet room in a second floor 1910...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30</td>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6976</td>\n",
       "      <td>https://www.airbnb.com/rooms/6976</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Mexican Folk Art Haven in Boston</td>\n",
       "      <td>Come stay with a friendly, middle-aged guy in ...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1436513</td>\n",
       "      <td>https://www.airbnb.com/rooms/1436513</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Spacious Sunny Bedroom Suite in Historic Home</td>\n",
       "      <td>Come experience the comforts of home away from...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>flexible</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7651065</td>\n",
       "      <td>https://www.airbnb.com/rooms/7651065</td>\n",
       "      <td>20160906204935</td>\n",
       "      <td>2016-09-07</td>\n",
       "      <td>Come Home to Boston</td>\n",
       "      <td>My comfy, clean and relaxing home is one block...</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>9.237421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index cancellation_policy  review_scores_value        id  \\\n",
       "0        0      0            moderate                  NaN  12147973   \n",
       "1        1      1            moderate                  9.0   3075044   \n",
       "2        2      2            moderate                 10.0      6976   \n",
       "3        3      3            moderate                 10.0   1436513   \n",
       "4        4      4            flexible                 10.0   7651065   \n",
       "\n",
       "                             listing_url       scrape_id last_scraped  \\\n",
       "0  https://www.airbnb.com/rooms/12147973  20160906204935   2016-09-07   \n",
       "1   https://www.airbnb.com/rooms/3075044  20160906204935   2016-09-07   \n",
       "2      https://www.airbnb.com/rooms/6976  20160906204935   2016-09-07   \n",
       "3   https://www.airbnb.com/rooms/1436513  20160906204935   2016-09-07   \n",
       "4   https://www.airbnb.com/rooms/7651065  20160906204935   2016-09-07   \n",
       "\n",
       "                                            name  \\\n",
       "0                     Sunny Bungalow in the City   \n",
       "1              Charming room in pet friendly apt   \n",
       "2               Mexican Folk Art Haven in Boston   \n",
       "3  Spacious Sunny Bedroom Suite in Historic Home   \n",
       "4                            Come Home to Boston   \n",
       "\n",
       "                                             summary  ...  \\\n",
       "0  Cozy, sunny, family home.  Master bedroom high...  ...   \n",
       "1  Charming and quiet room in a second floor 1910...  ...   \n",
       "2  Come stay with a friendly, middle-aged guy in ...  ...   \n",
       "3  Come experience the comforts of home away from...  ...   \n",
       "4  My comfy, clean and relaxing home is one block...  ...   \n",
       "\n",
       "  review_scores_location requires_license license jurisdiction_names  \\\n",
       "0                    NaN                f     NaN                NaN   \n",
       "1                    9.0                f     NaN                NaN   \n",
       "2                    9.0                f     NaN                NaN   \n",
       "3                   10.0                f     NaN                NaN   \n",
       "4                    9.0                f     NaN                NaN   \n",
       "\n",
       "  instant_bookable require_guest_profile_picture  \\\n",
       "0                f                             f   \n",
       "1                t                             f   \n",
       "2                f                             t   \n",
       "3                f                             f   \n",
       "4                f                             f   \n",
       "\n",
       "  require_guest_phone_verification calculated_host_listings_count  \\\n",
       "0                                f                              1   \n",
       "1                                f                              1   \n",
       "2                                f                              1   \n",
       "3                                f                              1   \n",
       "4                                f                              1   \n",
       "\n",
       "  reviews_per_month mean_review_scores  \n",
       "0               NaN           9.307398  \n",
       "1              1.30           9.307398  \n",
       "2              0.47           9.307398  \n",
       "3              1.00           9.307398  \n",
       "4              2.25           9.237421  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For instance, if we only awant those groups which have a mean rating above 9 included in our results\n",
    "df.groupby('cancellation_policy').filter(lambda x: np.mean(x['review_scores_value'])>9.2).head()\n",
    "# Notice that the results are still indexed, but that any of the results which were in a group with a mean review score of less than or equal to 9.2 were not copied over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8811e7-a7af-4aca-8c54-e6bd2109eb70",
   "metadata": {},
   "source": [
    "### Applying\n",
    "By far the most common operation I invoke on groupby objects is the apply function. This allows you to apply an arbitrary function to each group, and stitch the results back for each apply() into a single dataframe where the index is preserved. Let's look at an example using our airbnb data, I'm going to get a clean vopy of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "76d88256-eb59-4fc4-93ff-2cd653faafe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>review_scores_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moderate</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moderate</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flexible</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cancellation_policy  review_scores_value\n",
       "0            moderate                  NaN\n",
       "1            moderate                  9.0\n",
       "2            moderate                 10.0\n",
       "3            moderate                 10.0\n",
       "4            flexible                 10.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"data/listings.csv\")\n",
    "# And lets just include some of the columns we were interested in previously\n",
    "df=df[['cancellation_policy','review_scores_value']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4c312257-56ba-4673-a633-badc868f1f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancellation_policy</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>review_scores_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>moderate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moderate</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.307398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.692602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>moderate</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.692602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flexible</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.762579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cancellation_policy  review_scores_value  review_scores_mean\n",
       "0            moderate                  NaN                 NaN\n",
       "1            moderate                  9.0            0.307398\n",
       "2            moderate                 10.0            0.692602\n",
       "3            moderate                 10.0            0.692602\n",
       "4            flexible                 10.0            0.762579"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In previous work we wanted to find the average review score of a listing and its deviation from the group mean. This was a two process, first we use transform() on the groupby object and then we \n",
    "# had to broadcast to creat a new column. With apply() we could wrap this logic in one place\n",
    "def calc_mean_review_scores(group):\n",
    "    avg = np.nanmean(group['review_scores_value'])\n",
    "    group[\"review_scores_mean\"]=np.abs(avg-group[\"review_scores_value\"])\n",
    "    return group\n",
    "df.groupby('cancellation_policy').apply(calc_mean_review_scores).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "23e0d4d4-6dba-4da9-87fe-20c77303ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using apply can be slower than using some of the specialized functions, especially agg(). But, if your dataframes are not huge, it's a solid general purpose approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a86793-65a0-4dad-aafb-55bb1c5aa0a4",
   "metadata": {},
   "source": [
    "# Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "392d4054-9dc4-419c-9bc2-961645914268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>A+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>A-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>B+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>C-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>D+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Grades\n",
       "excellent     A+\n",
       "excellent      A\n",
       "excellent     A-\n",
       "good          B+\n",
       "good           B\n",
       "good          B-\n",
       "ok            C+\n",
       "ok             C\n",
       "ok            C-\n",
       "poor          D+\n",
       "poor           D"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's an example. Lets create a dataframe of letter grades in descending order. We can also set an index value and here we'll just make it some human judgement of how good a student was, like\n",
    "# \"excellent\" or \"good\"\n",
    "\n",
    "df = pd.DataFrame(['A+', 'A', 'A-', 'B+', 'B', 'B-', 'C+', 'C', 'C-', 'D+', 'D'], index = ['excellent', 'excellent', 'excellent', 'good', 'good', 'good', 'ok', 'ok', 'ok', 'poor', 'poor'],\n",
    "                  columns = ['Grades'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "80cd38d8-3616-4e3c-b0ce-ee800458b022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grades    object\n",
      "dtype: object\n",
      "excellent    A+\n",
      "excellent     A\n",
      "excellent    A-\n",
      "good         B+\n",
      "good          B\n",
      "Name: Grades, dtype: category\n",
      "Categories (11, object): ['A', 'A+', 'A-', 'B', ..., 'C+', 'C-', 'D', 'D+']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "excellent    A+\n",
       "excellent     A\n",
       "excellent    A-\n",
       "good         B+\n",
       "good          B\n",
       "Name: Grades, dtype: category\n",
       "Categories (11, object): ['D' < 'D+' < 'C-' < 'C' ... 'B+' < 'A-' < 'A' < 'A+']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, if we checj the datatype of this column, we see that it's just an object, since we set string values\n",
    "print(df.dtypes)\n",
    "# We can, however, tell pandas that we want to change the type to category, using the astype() function\n",
    "print(df['Grades'].astype(\"category\").head())\n",
    "# We see now that there are eleven categories, and pandas is aware of what those categories are. More interesting though is that our data isn't just categorical, but that it's ordered. That is, an A-\n",
    "# come after a B+, and B comes before a B+. We can tell pandas that the data is ordered by first creating a new categorical data type with the list of the categories (in order) and the ordered = \n",
    "# true flag\n",
    "my_categories = pd.CategoricalDtype(categories = ['D', 'D+', 'C-', 'C', 'C+', 'B-', 'B', 'B+', 'A-', 'A', 'A+'], ordered=True)\n",
    "grades = df['Grades'].astype(my_categories)\n",
    "grades.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75282d8-9e94-44e7-ba69-33a57896a574",
   "metadata": {},
   "source": [
    "Now we see that pandas is not only aware that there are 11 categories, but it is also aware of the order of those categoreies. So, what can you do with this? Well because there is an ordering this can help with comparisons and boolean masking. For instance, if we have a list of our grades and we compare them to a \"C\" we see that the lexicographical comparison returns results we were not intending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "544531f3-1518-403f-911e-f17d08595e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Grades\n",
      "ok       C+\n",
      "ok       C-\n",
      "poor     D+\n",
      "poor      D\n",
      "excellent    A+\n",
      "excellent     A\n",
      "excellent    A-\n",
      "good         B+\n",
      "good          B\n",
      "good         B-\n",
      "ok           C+\n",
      "Name: Grades, dtype: category\n",
      "Categories (11, object): ['D' < 'D+' < 'C-' < 'C' ... 'B+' < 'A-' < 'A' < 'A+']\n"
     ]
    }
   ],
   "source": [
    "print(df[df['Grades']>'C'])\n",
    "# So a C+ is grat than a C, but a C- and D certinly are not. However, if we broadcast over the dataframe which has the type set to an ordered categorical \n",
    "print(grades[grades>'C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a694fb8d-35cb-4068-aa3a-d7ef7f5a1b11",
   "metadata": {},
   "source": [
    "We see that the operator works as we would expect. We can the use a certain set of mathematical operators, like minimun, maximun, etc., on the ordinal data. Sometime it is useful to represent categorical values as each being a column with a true or a false as to whether the category applies. This is especially common in feature extraction, which is a topic in the data mining course. Variables with a boolean value are typically called dummy variables, and pandas has a built in function called get_dummies chich will convert the values of a single column into multiple columns of zeros and ones indicating the presence of the dummy variable. I rarely use it, but when I do it's very handy.\n",
    "There's one more common scale-based operation I'd like to talk about, and that's on converting a scale from something that is on the interval or ratio scale, like a numeric grade, into one chich is categorical. Now, this might seem a bit counter intuitive to you, since you are losing information about the value. But it's this can be an extremely useful approach, and histograms are regularly used with converted inverval or ratio data. In addition, if you're usign a machine learning classification approach on data, you need to be using categorical data, so reducing dimensionality may be useful just to apply a given technique. Pandas has a fucntion called cut which takes as an argument some array-like structure like a column of a dataframe or a series. It also takes a number of bins to used and all bins are kept at equal spacing. Lets goback to our census data for an example. We saw that we could group by state, the aggregate to get a list of the average county size by state. If we futher apply cut to this with, say, ten bins, we can see the states listed as categoricals using the average county size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ee1d0f23-29a1-4e20-b710-deea3cfbf295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STNAME\n",
       "Alabama        71339.343284\n",
       "Alaska         24490.724138\n",
       "Arizona       426134.466667\n",
       "Arkansas       38878.906667\n",
       "California    642309.586207\n",
       "Name: CENSUS2010POP, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we read in our dataset\n",
    "df=pd.read_csv(\"data/census.csv\")\n",
    "\n",
    "# And we reduce this to country data\n",
    "df=df[df['SUMLEV']==50]\n",
    "\n",
    "# And for a few groups\n",
    "df=df.set_index('STNAME').groupby(level=0)['CENSUS2010POP'].agg(np.average)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2308d5b0-e63f-442f-99aa-4fabfddc2603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STNAME\n",
       "Alabama                   (11706.087, 75333.413]\n",
       "Alaska                    (11706.087, 75333.413]\n",
       "Arizona                 (390320.176, 453317.529]\n",
       "Arkansas                  (11706.087, 75333.413]\n",
       "California              (579312.234, 642309.586]\n",
       "Colorado                 (75333.413, 138330.766]\n",
       "Connecticut             (390320.176, 453317.529]\n",
       "Delaware                (264325.471, 327322.823]\n",
       "District of Columbia    (579312.234, 642309.586]\n",
       "Florida                 (264325.471, 327322.823]\n",
       "Georgia                   (11706.087, 75333.413]\n",
       "Hawaii                  (264325.471, 327322.823]\n",
       "Idaho                     (11706.087, 75333.413]\n",
       "Illinois                 (75333.413, 138330.766]\n",
       "Indiana                   (11706.087, 75333.413]\n",
       "Iowa                      (11706.087, 75333.413]\n",
       "Kansas                    (11706.087, 75333.413]\n",
       "Kentucky                  (11706.087, 75333.413]\n",
       "Louisiana                 (11706.087, 75333.413]\n",
       "Maine                    (75333.413, 138330.766]\n",
       "Maryland                (201328.118, 264325.471]\n",
       "Massachusetts           (453317.529, 516314.881]\n",
       "Michigan                 (75333.413, 138330.766]\n",
       "Minnesota                 (11706.087, 75333.413]\n",
       "Mississippi               (11706.087, 75333.413]\n",
       "Missouri                  (11706.087, 75333.413]\n",
       "Montana                   (11706.087, 75333.413]\n",
       "Nebraska                  (11706.087, 75333.413]\n",
       "Nevada                  (138330.766, 201328.118]\n",
       "New Hampshire            (75333.413, 138330.766]\n",
       "New Jersey              (390320.176, 453317.529]\n",
       "New Mexico                (11706.087, 75333.413]\n",
       "New York                (264325.471, 327322.823]\n",
       "North Carolina           (75333.413, 138330.766]\n",
       "North Dakota              (11706.087, 75333.413]\n",
       "Ohio                     (75333.413, 138330.766]\n",
       "Oklahoma                  (11706.087, 75333.413]\n",
       "Oregon                   (75333.413, 138330.766]\n",
       "Pennsylvania            (138330.766, 201328.118]\n",
       "Rhode Island            (201328.118, 264325.471]\n",
       "South Carolina           (75333.413, 138330.766]\n",
       "South Dakota              (11706.087, 75333.413]\n",
       "Tennessee                 (11706.087, 75333.413]\n",
       "Texas                    (75333.413, 138330.766]\n",
       "Utah                     (75333.413, 138330.766]\n",
       "Vermont                   (11706.087, 75333.413]\n",
       "Virginia                  (11706.087, 75333.413]\n",
       "Washington              (138330.766, 201328.118]\n",
       "West Virginia             (11706.087, 75333.413]\n",
       "Wisconsin                (75333.413, 138330.766]\n",
       "Wyoming                   (11706.087, 75333.413]\n",
       "Name: CENSUS2010POP, dtype: category\n",
       "Categories (10, interval[float64, right]): [(11706.087, 75333.413] < (75333.413, 138330.766] < (138330.766, 201328.118] < (201328.118, 264325.471] ... (390320.176, 453317.529] < (453317.529, 516314.881] < (516314.881, 579312.234] < (579312.234, 642309.586]]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(df, 10) # Cut values in 10 groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "14d8e4d6-d252-407a-a812-0bd41b70d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we see that states like alabama and alaska fall into the same category, while california and the disctrict of columnbia fall in a very different category. Now, cutting is just one way to\n",
    "# build categories from your data, and there are many other methods. For instance, cut gives you interval data, where the spacing between each category is equal sized. but sometimes you want\n",
    "# to from categories bases on frecquency - you want the number of items in each bin to the be the same, instead of the spacing between bins. It really depens on what the shape of your data is, and \n",
    "# what you're planning to do with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161e329d-e473-428f-9b18-1f100a09a5e2",
   "metadata": {},
   "source": [
    "# Pivot Table\n",
    "A pivot table is a way of summatizing data in a DataFrame for a particular purpose. It makes heavy use of the aggregation function. A pivot table is itself a Dataframe, where the rows represent one variable that you're interested in, the columns another, and the cell's some aggregate value. A pivot table also tends to incluedes marginal values as well, which are the sums for each column and row. This allows you to be able to see the relationship between two variables at just a glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5da5d279-dfc1-4222-ad6e-c5a3a76ed4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>institution</th>\n",
       "      <th>country</th>\n",
       "      <th>national_rank</th>\n",
       "      <th>quality_of_education</th>\n",
       "      <th>alumni_employment</th>\n",
       "      <th>quality_of_faculty</th>\n",
       "      <th>publications</th>\n",
       "      <th>influence</th>\n",
       "      <th>citations</th>\n",
       "      <th>broad_impact</th>\n",
       "      <th>patents</th>\n",
       "      <th>score</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>91.67</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>USA</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>89.50</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>86.17</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>85.21</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                            institution         country  \\\n",
       "0           1                     Harvard University             USA   \n",
       "1           2  Massachusetts Institute of Technology             USA   \n",
       "2           3                    Stanford University             USA   \n",
       "3           4                University of Cambridge  United Kingdom   \n",
       "4           5     California Institute of Technology             USA   \n",
       "\n",
       "   national_rank  quality_of_education  alumni_employment  quality_of_faculty  \\\n",
       "0              1                     7                  9                   1   \n",
       "1              2                     9                 17                   3   \n",
       "2              3                    17                 11                   5   \n",
       "3              1                    10                 24                   4   \n",
       "4              4                     2                 29                   7   \n",
       "\n",
       "   publications  influence  citations  broad_impact  patents   score  year  \n",
       "0             1          1          1           NaN        5  100.00  2012  \n",
       "1            12          4          4           NaN        1   91.67  2012  \n",
       "2             4          2          2           NaN       15   89.50  2012  \n",
       "3            16         16         11           NaN       50   86.17  2012  \n",
       "4            37         22         22           NaN       18   85.21  2012  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we have the Times Higher Education World University Ranking dataset, which is one of the most influential university measures. Let's import the dataset and see what it looks like\n",
    "df = pd.read_csv('data/cwurData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "558bbb87-0e44-4f31-9bc1-2be7a1737892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>institution</th>\n",
       "      <th>country</th>\n",
       "      <th>national_rank</th>\n",
       "      <th>quality_of_education</th>\n",
       "      <th>alumni_employment</th>\n",
       "      <th>quality_of_faculty</th>\n",
       "      <th>publications</th>\n",
       "      <th>influence</th>\n",
       "      <th>citations</th>\n",
       "      <th>broad_impact</th>\n",
       "      <th>patents</th>\n",
       "      <th>score</th>\n",
       "      <th>year</th>\n",
       "      <th>Rank_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>USA</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2012</td>\n",
       "      <td>First Tier Top Unversity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>91.67</td>\n",
       "      <td>2012</td>\n",
       "      <td>First Tier Top Unversity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>USA</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>89.50</td>\n",
       "      <td>2012</td>\n",
       "      <td>First Tier Top Unversity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>86.17</td>\n",
       "      <td>2012</td>\n",
       "      <td>First Tier Top Unversity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>USA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>85.21</td>\n",
       "      <td>2012</td>\n",
       "      <td>First Tier Top Unversity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                            institution         country  \\\n",
       "0           1                     Harvard University             USA   \n",
       "1           2  Massachusetts Institute of Technology             USA   \n",
       "2           3                    Stanford University             USA   \n",
       "3           4                University of Cambridge  United Kingdom   \n",
       "4           5     California Institute of Technology             USA   \n",
       "\n",
       "   national_rank  quality_of_education  alumni_employment  quality_of_faculty  \\\n",
       "0              1                     7                  9                   1   \n",
       "1              2                     9                 17                   3   \n",
       "2              3                    17                 11                   5   \n",
       "3              1                    10                 24                   4   \n",
       "4              4                     2                 29                   7   \n",
       "\n",
       "   publications  influence  citations  broad_impact  patents   score  year  \\\n",
       "0             1          1          1           NaN        5  100.00  2012   \n",
       "1            12          4          4           NaN        1   91.67  2012   \n",
       "2             4          2          2           NaN       15   89.50  2012   \n",
       "3            16         16         11           NaN       50   86.17  2012   \n",
       "4            37         22         22           NaN       18   85.21  2012   \n",
       "\n",
       "                 Rank_Level  \n",
       "0  First Tier Top Unversity  \n",
       "1  First Tier Top Unversity  \n",
       "2  First Tier Top Unversity  \n",
       "3  First Tier Top Unversity  \n",
       "4  First Tier Top Unversity  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can see each institutiopn's rank, country, quality of education, other metrics, and overall score. Let's say we want to create a new column called Rank_Level, where institutions with world\n",
    "# ranking 1-100 are categorized as first tier and those with world ranking 101 - 200 are second tier, ranking 201 -300 are third tier, after 301 is other top universities.\n",
    "def create_category(ranking):\n",
    "    # Since the rank is just an integer, I'll just do a bunch of if/elif statements\n",
    "    if (ranking >= 1) & (ranking <= 100):\n",
    "        return \"First Tier Top Unversity\"\n",
    "    elif (ranking >= 101) & (ranking <= 200):\n",
    "        return \"Second Tier Top Unversity\"\n",
    "    elif (ranking >= 201) & (ranking <= 300):\n",
    "        return \"Third Tier Top Unversity\"\n",
    "    return \"Other Top Unversity\"\n",
    "df['Rank_Level'] = df['world_rank'].apply(lambda x: create_category(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f0f532ab-02eb-40e1-9c7c-b7c36927bf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">nanmean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank_Level</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <th>Third Tier Top Unversity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.672857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>47.9425</td>\n",
       "      <td>44.645750</td>\n",
       "      <td>49.2425</td>\n",
       "      <td>47.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.864286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium</th>\n",
       "      <td>51.8750</td>\n",
       "      <td>45.081000</td>\n",
       "      <td>49.0840</td>\n",
       "      <td>46.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.499706</td>\n",
       "      <td>49.5650</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            nanmean                      \\\n",
       "Rank_Level First Tier Top Unversity Other Top Unversity   \n",
       "country                                                   \n",
       "Argentina                       NaN           44.672857   \n",
       "Australia                   47.9425           44.645750   \n",
       "Austria                         NaN           44.864286   \n",
       "Belgium                     51.8750           45.081000   \n",
       "Brazil                          NaN           44.499706   \n",
       "\n",
       "                                                               \n",
       "Rank_Level Second Tier Top Unversity Third Tier Top Unversity  \n",
       "country                                                        \n",
       "Argentina                        NaN                      NaN  \n",
       "Australia                    49.2425                47.285000  \n",
       "Austria                          NaN                47.066667  \n",
       "Belgium                      49.0840                46.746667  \n",
       "Brazil                       49.5650                      NaN  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A pivot table allows us to pivot out one of these columns a new column headers and compare it against another column as row indices. Let's say we wanto to caompare rank level versus country of the\n",
    "# universities and we want to compare in terms of overll score. To do this, we tell Pandas we want the values to be Score, and index to be the country and the columns to be the rank levels. Then\n",
    "# we specify that the aggregation function, and here we'll use the Numpy mean to get the average rating for universities in tha country\n",
    "df.pivot_table(values = 'score', index = 'country', columns = 'Rank_Level', aggfunc = [np.nanmean]).head()\n",
    "# We can see a hierarchical dataframe where the index, or rows, are by country and the columns have two levels, the top level indicating that the mean value is being used and the second level being\n",
    "# our ranks. In this example we only have one variable, the mean, that we are looking at, so we don't really need a hierarchical index. We notice that there are somne nan values, for example the\n",
    "# first row, Argentina. The Nan values indicate that argentina has only observations in \"The other top universities\" category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8c11780e-e8af-4cc8-8062-21432a97afdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">nanmean</th>\n",
       "      <th colspan=\"4\" halign=\"left\">amax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank_Level</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <th>Third Tier Top Unversity</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <th>Third Tier Top Unversity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.672857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>47.9425</td>\n",
       "      <td>44.645750</td>\n",
       "      <td>49.2425</td>\n",
       "      <td>47.285000</td>\n",
       "      <td>51.61</td>\n",
       "      <td>45.97</td>\n",
       "      <td>50.40</td>\n",
       "      <td>47.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.864286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.066667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium</th>\n",
       "      <td>51.8750</td>\n",
       "      <td>45.081000</td>\n",
       "      <td>49.0840</td>\n",
       "      <td>46.746667</td>\n",
       "      <td>52.03</td>\n",
       "      <td>46.21</td>\n",
       "      <td>49.73</td>\n",
       "      <td>47.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.499706</td>\n",
       "      <td>49.5650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.08</td>\n",
       "      <td>49.82</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            nanmean                      \\\n",
       "Rank_Level First Tier Top Unversity Other Top Unversity   \n",
       "country                                                   \n",
       "Argentina                       NaN           44.672857   \n",
       "Australia                   47.9425           44.645750   \n",
       "Austria                         NaN           44.864286   \n",
       "Belgium                     51.8750           45.081000   \n",
       "Brazil                          NaN           44.499706   \n",
       "\n",
       "                                                               \\\n",
       "Rank_Level Second Tier Top Unversity Third Tier Top Unversity   \n",
       "country                                                         \n",
       "Argentina                        NaN                      NaN   \n",
       "Australia                    49.2425                47.285000   \n",
       "Austria                          NaN                47.066667   \n",
       "Belgium                      49.0840                46.746667   \n",
       "Brazil                       49.5650                      NaN   \n",
       "\n",
       "                               amax                      \\\n",
       "Rank_Level First Tier Top Unversity Other Top Unversity   \n",
       "country                                                   \n",
       "Argentina                       NaN               45.66   \n",
       "Australia                     51.61               45.97   \n",
       "Austria                         NaN               46.29   \n",
       "Belgium                       52.03               46.21   \n",
       "Brazil                          NaN               46.08   \n",
       "\n",
       "                                                               \n",
       "Rank_Level Second Tier Top Unversity Third Tier Top Unversity  \n",
       "country                                                        \n",
       "Argentina                        NaN                      NaN  \n",
       "Australia                      50.40                    47.47  \n",
       "Austria                          NaN                    47.78  \n",
       "Belgium                        49.73                    47.14  \n",
       "Brazil                         49.82                      NaN  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now pivot tables aren't limited to one function that you might want to apply. You can pass a named parameter, aggfunc, which is a list of the different functions to apply, and pandas will \n",
    "# provide you with the result using hierarchical column names. Let's try that same query, but áss ion the max function too\n",
    "df.pivot_table(values = 'score', index = 'country', columns = 'Rank_Level', aggfunc = [np.nanmean, np.max]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e83d57d1-ca92-4817-b5d1-fafd01521697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">mean</th>\n",
       "      <th colspan=\"5\" halign=\"left\">amax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank_Level</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <th>Third Tier Top Unversity</th>\n",
       "      <th>All</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <th>Third Tier Top Unversity</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.672857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.672857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>47.9425</td>\n",
       "      <td>44.645750</td>\n",
       "      <td>49.2425</td>\n",
       "      <td>47.285000</td>\n",
       "      <td>45.825517</td>\n",
       "      <td>51.61</td>\n",
       "      <td>45.97</td>\n",
       "      <td>50.40</td>\n",
       "      <td>47.47</td>\n",
       "      <td>51.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.864286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.066667</td>\n",
       "      <td>45.139583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.78</td>\n",
       "      <td>47.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium</th>\n",
       "      <td>51.8750</td>\n",
       "      <td>45.081000</td>\n",
       "      <td>49.0840</td>\n",
       "      <td>46.746667</td>\n",
       "      <td>47.011000</td>\n",
       "      <td>52.03</td>\n",
       "      <td>46.21</td>\n",
       "      <td>49.73</td>\n",
       "      <td>47.14</td>\n",
       "      <td>52.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>NaN</td>\n",
       "      <td>44.499706</td>\n",
       "      <td>49.5650</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.781111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.08</td>\n",
       "      <td>49.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               mean                      \\\n",
       "Rank_Level First Tier Top Unversity Other Top Unversity   \n",
       "country                                                   \n",
       "Argentina                       NaN           44.672857   \n",
       "Australia                   47.9425           44.645750   \n",
       "Austria                         NaN           44.864286   \n",
       "Belgium                     51.8750           45.081000   \n",
       "Brazil                          NaN           44.499706   \n",
       "\n",
       "                                                                          \\\n",
       "Rank_Level Second Tier Top Unversity Third Tier Top Unversity        All   \n",
       "country                                                                    \n",
       "Argentina                        NaN                      NaN  44.672857   \n",
       "Australia                    49.2425                47.285000  45.825517   \n",
       "Austria                          NaN                47.066667  45.139583   \n",
       "Belgium                      49.0840                46.746667  47.011000   \n",
       "Brazil                       49.5650                      NaN  44.781111   \n",
       "\n",
       "                               amax                      \\\n",
       "Rank_Level First Tier Top Unversity Other Top Unversity   \n",
       "country                                                   \n",
       "Argentina                       NaN               45.66   \n",
       "Australia                     51.61               45.97   \n",
       "Austria                         NaN               46.29   \n",
       "Belgium                       52.03               46.21   \n",
       "Brazil                          NaN               46.08   \n",
       "\n",
       "                                                                      \n",
       "Rank_Level Second Tier Top Unversity Third Tier Top Unversity    All  \n",
       "country                                                               \n",
       "Argentina                        NaN                      NaN  45.66  \n",
       "Australia                      50.40                    47.47  51.61  \n",
       "Austria                          NaN                    47.78  47.78  \n",
       "Belgium                        49.73                    47.14  52.03  \n",
       "Brazil                         49.82                      NaN  49.82  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So now we see we have both the man an the max. As mentioned earlier, we can also summarize the values within a given top level column. For instance, if we want to see an overall averange for the\n",
    "# mean and we ant see the max of the max, we can indicate that we want pandas to provide marginal values\n",
    "df.pivot_table(values='score', index='country', columns='Rank_Level', aggfunc=[np.mean, np.max], margins=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b0e1f325-77b7-4009-978f-6f6da2d62a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Argentina', 'Australia', 'Austria', 'Belgium', 'Brazil', 'Bulgaria',\n",
      "       'Canada', 'Chile', 'China', 'Colombia', 'Croatia', 'Cyprus',\n",
      "       'Czech Republic', 'Denmark', 'Egypt', 'Estonia', 'Finland', 'France',\n",
      "       'Germany', 'Greece', 'Hong Kong', 'Hungary', 'Iceland', 'India', 'Iran',\n",
      "       'Ireland', 'Israel', 'Italy', 'Japan', 'Lebanon', 'Lithuania',\n",
      "       'Malaysia', 'Mexico', 'Netherlands', 'New Zealand', 'Norway', 'Poland',\n",
      "       'Portugal', 'Puerto Rico', 'Romania', 'Russia', 'Saudi Arabia',\n",
      "       'Serbia', 'Singapore', 'Slovak Republic', 'Slovenia', 'South Africa',\n",
      "       'South Korea', 'Spain', 'Sweden', 'Switzerland', 'Taiwan', 'Thailand',\n",
      "       'Turkey', 'USA', 'Uganda', 'United Arab Emirates', 'United Kingdom',\n",
      "       'Uruguay', 'All'],\n",
      "      dtype='object', name='country')\n",
      "MultiIndex([('mean',  'First Tier Top Unversity'),\n",
      "            ('mean',       'Other Top Unversity'),\n",
      "            ('mean', 'Second Tier Top Unversity'),\n",
      "            ('mean',  'Third Tier Top Unversity'),\n",
      "            ('mean',                       'All'),\n",
      "            ('amax',  'First Tier Top Unversity'),\n",
      "            ('amax',       'Other Top Unversity'),\n",
      "            ('amax', 'Second Tier Top Unversity'),\n",
      "            ('amax',  'Third Tier Top Unversity'),\n",
      "            ('amax',                       'All')],\n",
      "           names=[None, 'Rank_Level'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "country\n",
       "Argentina        NaN\n",
       "Australia    47.9425\n",
       "Austria          NaN\n",
       "Belgium      51.8750\n",
       "Brazil           NaN\n",
       "Name: First Tier Top Unversity, dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A pivot table is just a multi-level dataframe and we can access series or cells in the datafrmae in a similar way as we do so for a regular dataframe\n",
    "new_df=df.pivot_table(values='score', index='country', columns='Rank_Level', aggfunc=[np.mean, np.max], margins=True)\n",
    "# Now let's look at the index\n",
    "print(new_df.index)\n",
    "# And let's look at the columns\n",
    "print(new_df.columns)\n",
    "# We can see the columns are hierarchical. The top level column indices have two categories: mean and max, and the lower level column indices have four categories, chich are the four rank leves.\n",
    "# How would we query this if we want to get the average scores of first tier top university levels in each country? We would just need to maje two dataframe projections, the first for the mean,\n",
    "# then the second for the top tier\n",
    "new_df['mean']['First Tier Top Unversity'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "67f31916-77da-4e79-8342-8271d10ff8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United Kingdom'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What if we want to find the country that has the maximun average score on First Tier Top University level?\n",
    "# We can use the idexmax() function\n",
    "new_df['mean']['First Tier Top Unversity'].idxmax()\n",
    "# Now, the idxmax() function isn't special for pivot tables. If you want to achieve a different shape of your pivot table, you can do so with the stack and unstack function. Stacking is pivoting the\n",
    "# lowermost column index to vecome the innermost row index. Unstacjking is the inverse of stacking, pivotinf the innermost row index to become the lowermost column index. An example will help make\n",
    "# this clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "404f3492-e49d-4126-987a-27469bc245c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>amax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th>Rank_Level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Argentina</th>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <td>44.672857</td>\n",
       "      <td>45.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>44.672857</td>\n",
       "      <td>45.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Australia</th>\n",
       "      <th>First Tier Top Unversity</th>\n",
       "      <td>47.942500</td>\n",
       "      <td>51.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Top Unversity</th>\n",
       "      <td>44.645750</td>\n",
       "      <td>45.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second Tier Top Unversity</th>\n",
       "      <td>49.242500</td>\n",
       "      <td>50.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          mean   amax\n",
       "country   Rank_Level                                 \n",
       "Argentina Other Top Unversity        44.672857  45.66\n",
       "          All                        44.672857  45.66\n",
       "Australia First Tier Top Unversity   47.942500  51.61\n",
       "          Other Top Unversity        44.645750  45.97\n",
       "          Second Tier Top Unversity  49.242500  50.40"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.stack().head()# The columns tier convert in lower index in rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "27cf61df-b5d4-45cf-a5b7-ba226d3c64c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Rank_Level                country  \n",
       "mean  First Tier Top Unversity  Argentina        NaN\n",
       "                                Australia    47.9425\n",
       "                                Austria          NaN\n",
       "                                Belgium      51.8750\n",
       "                                Brazil           NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.unstack().head()# The columns tier convert in lower index in rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "359d1807-8c55-474d-8634-5c0370335402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Rank_Level                country             \n",
       "mean  First Tier Top Unversity  Argentina                    NaN\n",
       "                                Australia                47.9425\n",
       "                                Austria                      NaN\n",
       "                                Belgium                  51.8750\n",
       "                                Brazil                       NaN\n",
       "                                                          ...   \n",
       "amax  All                       Uganda                   44.4000\n",
       "                                United Arab Emirates     44.3600\n",
       "                                United Kingdom           97.6400\n",
       "                                Uruguay                  44.3500\n",
       "                                All                     100.0000\n",
       "Length: 600, dtype: float64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.unstack() # the rows convert in columns in one column with multiple indexes and only one value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6395edf-0d02-4663-8218-ea85739811e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Timestamp\n",
    "In today's lecture, where we'll be looking at the time series and date functionally in pandas. Manipulating dates and time is quite flexible in Pandas and thus allows us to conduct more analysis such as time series analysis, which we will talk about soon. Actually, pandas was originally created by Wed MecKinney to handle data and time data when worked as a consultant for hedge funds.\n",
    "Pandas has four main time related classes. Timestamp, DatatimeIndex, Period, and PeriodIndex. First, let's look a timestamp. It represents a single timestamp using a string 9/1/2019 10:05AM, and here we have iour timestamp. Timestamp is interchangable with python's datetime in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ab7d43-3394-485e-8903-5480fb8ccaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-01 10:05:00\n",
      "2022-05-02 10:05:00\n",
      "2019-12-20 00:00:00\n",
      "5\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "print(pd.Timestamp('9/1/2019 10:05AM'))\n",
    "print(pd.Timestamp('10:05')) # With today\n",
    "print(pd.Timestamp(2019, 12, 20, 0, 0)) # Pass year,month, day, etc\n",
    "print(pd.Timestamp(2019, 12, 20, 0, 0).isoweekday()) # Timestamp also has some useful attributes, cuch as isoweekday(), which shows the weekday of the timestamp, note tha 1 reprsents Monday and 7 Sunday\n",
    "print(pd.Timestamp(2019, 12, 20, 5, 2,23).second) # You can find extract the specific year, month, day, hour, minute, second from a timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63746ba-912a-40e4-806e-be188db15995",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Period\n",
    "Suppose we weren't interested in a specific point in time and instead wanted a span of time. This is where the period class comes into play. Period represents a single time span, such as a specific day or month. He we are creating a preiod that is January 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d6db515-e7b0-4182-8954-3bbc36f8d4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01\n",
      "2016-03-05\n",
      "2016-06\n",
      "2016-03-03\n"
     ]
    }
   ],
   "source": [
    "print(pd.Period('1/2016'))\n",
    "# You will notice when we print that out the granualarity of the period is M for month, since that was the finest graines pice we provided. Here's an example of period that is March 5th, 2016.\n",
    "print(pd.Period('3/5/2016'))\n",
    "# Period object represent the full timespan that you specify. Arithmetic on period is very easy and intuitive, for instance, if we want to find out 5 months after January 2016, we simply plus 5\n",
    "print(pd.Period('1/2016') + 5)\n",
    "# From the result, you can see we get June 2016. If we want to find out two days before March 5th 2016, we simply subtract 2\n",
    "print(pd.Period('3/5/2016') - 2)\n",
    "# The key here is that the period object encpsulates the granualarity for arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29de799-ccf0-49f4-8d4a-939019d8fa7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DatetimeIndex and PeriodIndex\n",
    "The index of timestamp is DatetimeIndex. Let's look at quich example. First, let0s create our example series t1, we'll use the timestamp of september 1st, 2nd and 3rd of 2016. When we look at the series each timestamp is the index and has a value associated with it. in this case, a, b, c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1ce4dfd-a05c-4634-982c-69db5d4e76a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-09-01    a\n",
      "2016-09-02    b\n",
      "2016-09-03    c\n",
      "dtype: object\n",
      "<class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "2016-09    d\n",
      "2016-10    e\n",
      "2016-11    f\n",
      "Freq: M, dtype: object\n",
      "<class 'pandas.core.indexes.period.PeriodIndex'>\n"
     ]
    }
   ],
   "source": [
    "t1 = pd.Series(list('abc'), [pd.Timestamp('2016-09-01'), pd.Timestamp('2016-09-02'), pd.Timestamp('2016-09-03')])\n",
    "print(t1)\n",
    "print(type(t1.index))\n",
    "# Similarly, we can create a period-based index as well. \n",
    "t2 = pd.Series(list('def'), [pd.Period('2016-09'), pd.Period('2016-10'), pd.Period('2016-11')])\n",
    "print(t2)\n",
    "print(type(t2.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ce27c-d6af-48f1-b175-82f20b723826",
   "metadata": {},
   "source": [
    "## Converting to Datetime\n",
    "Now let's look into how to convert to Datetime. Suppose we have a list of dates as strings and we want to create a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1202f3a-eacd-466c-9338-3e8183a7f048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-06-02</th>\n",
       "      <td>66</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-08-29</th>\n",
       "      <td>35</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-26</th>\n",
       "      <td>40</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-12</th>\n",
       "      <td>82</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             a   b\n",
       "2013-06-02  66  17\n",
       "2014-08-29  35  27\n",
       "2015-06-26  40  57\n",
       "2016-07-12  82  40"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = ['2 June 2013', 'Aug 29, 2014', '2015-06-26', '7/12/16']\n",
    "ts3 = pd.DataFrame(np.random.randint(10, 100, (4,2)), index=d1, columns=list('ab'))\n",
    "# Using pandas to_datetime, pandas will try to convert these to Datetime and put them in a standard format.\n",
    "ts3.index = pd.to_datetime(ts3.index)\n",
    "ts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caa8a90f-fc74-4b72-b5cb-05a2428fd8ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2012-07-04 00:00:00')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to_datetime also() has options to change the date parse order. For example, we can pass in the argument dayfirst = True to parse the date in European date.\n",
    "pd.to_datetime('4.7.12', dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181c06ec-a89e-4afd-b77e-c78f5090ecaf",
   "metadata": {},
   "source": [
    "## Timedelta and Offset\n",
    "Timedeltas are differences in times. This is not same as a period, but conceptually similar. For instacen, if we want to taje the difference between september 3rd and september 1st, we get a timedelta of two days.\n",
    "Offset is similar to timedelta, but it followes specific calendar duration rules. Offset allows flecibility in terms of types of time intervals. Besides hour, bay, week, month, etc. It also has business day, end of month, semi month begin etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6d0adae-6140-4f87-aa4b-7e0dbcca1deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 days 00:00:00\n",
      "2016-09-14 11:10:00\n"
     ]
    }
   ],
   "source": [
    "print(pd.Timestamp('9/3/2016')-pd.Timestamp('9/1/2016'))\n",
    "# We can also do something like find what the date and time is for 12 days and three hours past September 2nd, at 8:10 AM.\n",
    "print(pd.Timestamp('9/2/2016 8:10AM') + pd.Timedelta('12D 3H'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "53a442db-c3f5-4c19-8767-2bb7feae617c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "2016-09-11 00:00:00\n",
      "2016-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(pd.Timestamp('9/4/2016').weekday())\n",
    "# Now we can now add the timestamp with a week ahead\n",
    "print(pd.Timestamp('9/4/2016') + pd.offsets.Week())\n",
    "# Now let's try to do the month end, then we would have the last day of Septemer\n",
    "print(pd.Timestamp('9/4/2016') + pd.offsets.MonthEnd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea950cb-1b34-435c-b99c-2da362b70af0",
   "metadata": {},
   "source": [
    "## Working with Dates in a Dataframe\n",
    "Next, let's look at a few tricks for working with dates in a DataFrame. Suppose we want to llok at nine measurements, taken bi weekly, every Sunday, starting in October 2016. Using date_rage, we can create this DatetimeIndex. In data_range, we have to either specify the start or end date. If it is not explicitly specified, by default, the date is considered the start date. Then we have to specify number of periods, and a frequency. Here, we set it to '2W-SUN', which means biweekly on Sunday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61d71b9f-f644-4b82-bacb-e35d1c4d5fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2016-10-02', '2016-10-16', '2016-10-30', '2016-11-13',\n",
      "               '2016-11-27', '2016-12-11', '2016-12-25', '2017-01-08',\n",
      "               '2017-01-22'],\n",
      "              dtype='datetime64[ns]', freq='2W-SUN')\n",
      "DatetimeIndex(['2016-10-03', '2016-10-04', '2016-10-05', '2016-10-06',\n",
      "               '2016-10-07', '2016-10-10', '2016-10-11', '2016-10-12',\n",
      "               '2016-10-13'],\n",
      "              dtype='datetime64[ns]', freq='B')\n",
      "DatetimeIndex(['2016-06-01', '2016-09-01', '2016-12-01', '2017-03-01',\n",
      "               '2017-06-01', '2017-09-01', '2017-12-01', '2018-03-01',\n",
      "               '2018-06-01', '2018-09-01', '2018-12-01', '2019-03-01'],\n",
      "              dtype='datetime64[ns]', freq='QS-JUN')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count 1</th>\n",
       "      <th>Count 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-10-02</th>\n",
       "      <td>104</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-16</th>\n",
       "      <td>104</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-30</th>\n",
       "      <td>99</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-13</th>\n",
       "      <td>101</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-27</th>\n",
       "      <td>97</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-11</th>\n",
       "      <td>101</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-25</th>\n",
       "      <td>97</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-08</th>\n",
       "      <td>106</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-22</th>\n",
       "      <td>108</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Count 1  Count 2\n",
       "2016-10-02      104      115\n",
       "2016-10-16      104      125\n",
       "2016-10-30       99      126\n",
       "2016-11-13      101      128\n",
       "2016-11-27       97      117\n",
       "2016-12-11      101      121\n",
       "2016-12-25       97      117\n",
       "2017-01-08      106      120\n",
       "2017-01-22      108      118"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.date_range('10-01-2016', periods = 9, freq = '2W-SUN')\n",
    "print(dates)\n",
    "# There are many other frequencies that you can specify. For example, you can do business day\n",
    "print(pd.date_range('10-01-2016', periods=9, freq='B'))\n",
    "# Or you can do quarterly, with the quarter start in June\n",
    "print(pd.date_range('04-01-2016', periods=12, freq='QS-JUN'))\n",
    "# Now, Let's go back to our weekly on Sunday example and create a DataFrame using these dates, and some random data, and see what we can do with it\n",
    "dates = pd.date_range('10-01-2016', periods=9, freq = '2W-SUN')\n",
    "df = pd.DataFrame({'Count 1': 100 + np.random.randint(-5, 10, 9).cumsum(), 'Count 2': 120 + np.random.randint(-5, 10, 9)}, index = dates)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4da9fc3a-01c5-41a0-b37a-b1b00565bda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([6, 6, 6, 6, 6, 6, 6, 6, 6], dtype='int64')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count 1</th>\n",
       "      <th>Count 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-10-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-30</th>\n",
       "      <td>-5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-27</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-11</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-25</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-08</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-22</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Count 1  Count 2\n",
       "2016-10-02      NaN      NaN\n",
       "2016-10-16      0.0     10.0\n",
       "2016-10-30     -5.0      1.0\n",
       "2016-11-13      2.0      2.0\n",
       "2016-11-27     -4.0    -11.0\n",
       "2016-12-11      4.0      4.0\n",
       "2016-12-25     -4.0     -4.0\n",
       "2017-01-08      9.0      3.0\n",
       "2017-01-22      2.0     -2.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we can check what day of the week a specific date is. For example, here we can see that all the dates in our index are on a Sunday. Which matches the freequency that we set\n",
    "print(df.index.weekday)\n",
    "# We can also use diff() to find the difference between each date's value.\n",
    "df.diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebaf9816-f963-4604-9d6a-b430831fc827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count 1</th>\n",
       "      <th>Count 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-10-31</th>\n",
       "      <td>102.333333</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-30</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>122.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-31</th>\n",
       "      <td>107.000000</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Count 1  Count 2\n",
       "2016-10-31  102.333333    122.0\n",
       "2016-11-30   99.000000    122.5\n",
       "2016-12-31   99.000000    119.0\n",
       "2017-01-31  107.000000    119.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppose we want to know what the mean count is for each month in our DataFRame. We can do this using resample. Converting from a higher frequency from a lower frequency is called downsapling (we'll \n",
    "# talk about this in a moment)\n",
    "df.resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7bb85be3-eb16-4bf9-be7b-976a0277daee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count 1</th>\n",
       "      <th>Count 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-08</th>\n",
       "      <td>106</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-22</th>\n",
       "      <td>108</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Count 1  Count 2\n",
       "2017-01-08      106      120\n",
       "2017-01-22      108      118"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's talk about datatime indexing and slicing, which is a wonderfull feature of the pandas DataFrame. For instance, we can use partial strinf indxing to find values from a particular year.\n",
    "df.loc['2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e5da92b-d3ab-4f2d-adad-a3b7c76bbacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count 1</th>\n",
       "      <th>Count 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-12-11</th>\n",
       "      <td>101</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-25</th>\n",
       "      <td>97</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Count 1  Count 2\n",
       "2016-12-11      101      121\n",
       "2016-12-25       97      117"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or we can do it from a particular month\n",
    "df.loc['2016-12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a0dc6ff-dc26-4e58-bd79-92ddb744f2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count 1</th>\n",
       "      <th>Count 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-12-11</th>\n",
       "      <td>101</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-25</th>\n",
       "      <td>97</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-08</th>\n",
       "      <td>106</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-22</th>\n",
       "      <td>108</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Count 1  Count 2\n",
       "2016-12-11      101      121\n",
       "2016-12-25       97      117\n",
       "2017-01-08      106      120\n",
       "2017-01-22      108      118"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or we can even slice on a range of dates For example, here we only want the values from December 2016 onwards.\n",
    "df['2016-12':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac93d9-10d4-412f-a0e7-2ca2abee9899",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
