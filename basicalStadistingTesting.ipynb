{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7b17c8-e301-40a0-9990-fb49e2419db7",
   "metadata": {},
   "source": [
    "# Stadistic testing\n",
    "In this notebooke we're going review some of the basics of statistical testing in python. We're going to talk about hypotesis testing, statistical significance, and using scipy to run student's t-tests.\n",
    "We use statistics in a lot of different ways in data science, and on this lectura, I want to refresh you knowledge of hypothesis testing, which is a core data analysis activity behind experimentation. The goal of hypothesis is to determine if, for instance, the two different conditions we have in an experiment have resulted in different impacts.\n",
    "Now, scipy is an interesting cikkectuib if libraries fo data science and you'll use most or perpahs all of these libraries. It incluedes numpy and pandas, but also plotting libraries such as matplotlib, and a number of scientific library functions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3d883a-bb8a-46e6-ba0b-8e063a95386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf36770-5398-4e11-940d-8e7af76df40b",
   "metadata": {},
   "source": [
    "When we do hyppothesus testing, we actually have two staements of interest: The fist is our actual explanation, whcich we call the alternative hypothesis, and the second is that explanation we have is no sufficient, and we call this the null hypothesis. Our testing method is to determine whether the null hypothesis is true or not. If we find that there is a difference between groups, then we can reject the null hypothesis and we accept our alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce04bb8f-62e8-4bf1-9158-a2586420bc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>assignment1_grade</th>\n",
       "      <th>assignment1_submission</th>\n",
       "      <th>assignment2_grade</th>\n",
       "      <th>assignment2_submission</th>\n",
       "      <th>assignment3_grade</th>\n",
       "      <th>assignment3_submission</th>\n",
       "      <th>assignment4_grade</th>\n",
       "      <th>assignment4_submission</th>\n",
       "      <th>assignment5_grade</th>\n",
       "      <th>assignment5_submission</th>\n",
       "      <th>assignment6_grade</th>\n",
       "      <th>assignment6_submission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B73F2C11-70F0-E37D-8B10-1D20AFED50B1</td>\n",
       "      <td>92.733946</td>\n",
       "      <td>2015-11-02 06:55:34.282000000</td>\n",
       "      <td>83.030552</td>\n",
       "      <td>2015-11-09 02:22:58.938000000</td>\n",
       "      <td>67.164441</td>\n",
       "      <td>2015-11-12 08:58:33.998000000</td>\n",
       "      <td>53.011553</td>\n",
       "      <td>2015-11-16 01:21:24.663000000</td>\n",
       "      <td>47.710398</td>\n",
       "      <td>2015-11-20 13:24:59.692000000</td>\n",
       "      <td>38.168318</td>\n",
       "      <td>2015-11-22 18:31:15.934000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98A0FAE0-A19A-13D2-4BB5-CFBFD94031D1</td>\n",
       "      <td>86.790821</td>\n",
       "      <td>2015-11-29 14:57:44.429000000</td>\n",
       "      <td>86.290821</td>\n",
       "      <td>2015-12-06 17:41:18.449000000</td>\n",
       "      <td>69.772657</td>\n",
       "      <td>2015-12-10 08:54:55.904000000</td>\n",
       "      <td>55.098125</td>\n",
       "      <td>2015-12-13 17:32:30.941000000</td>\n",
       "      <td>49.588313</td>\n",
       "      <td>2015-12-19 23:26:39.285000000</td>\n",
       "      <td>44.629482</td>\n",
       "      <td>2015-12-21 17:07:24.275000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D0F62040-CEB0-904C-F563-2F8620916C4E</td>\n",
       "      <td>85.512541</td>\n",
       "      <td>2016-01-09 05:36:02.389000000</td>\n",
       "      <td>85.512541</td>\n",
       "      <td>2016-01-09 06:39:44.416000000</td>\n",
       "      <td>68.410033</td>\n",
       "      <td>2016-01-15 20:22:45.882000000</td>\n",
       "      <td>54.728026</td>\n",
       "      <td>2016-01-11 12:41:50.749000000</td>\n",
       "      <td>49.255224</td>\n",
       "      <td>2016-01-11 17:31:12.489000000</td>\n",
       "      <td>44.329701</td>\n",
       "      <td>2016-01-17 16:24:42.765000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FFDF2B2C-F514-EF7F-6538-A6A53518E9DC</td>\n",
       "      <td>86.030665</td>\n",
       "      <td>2016-04-30 06:50:39.801000000</td>\n",
       "      <td>68.824532</td>\n",
       "      <td>2016-04-30 17:20:38.727000000</td>\n",
       "      <td>61.942079</td>\n",
       "      <td>2016-05-12 07:47:16.326000000</td>\n",
       "      <td>49.553663</td>\n",
       "      <td>2016-05-07 16:09:20.485000000</td>\n",
       "      <td>49.553663</td>\n",
       "      <td>2016-05-24 12:51:18.016000000</td>\n",
       "      <td>44.598297</td>\n",
       "      <td>2016-05-26 08:09:12.058000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5ECBEEB6-F1CE-80AE-3164-E45E99473FB4</td>\n",
       "      <td>64.813800</td>\n",
       "      <td>2015-12-13 17:06:10.750000000</td>\n",
       "      <td>51.491040</td>\n",
       "      <td>2015-12-14 12:25:12.056000000</td>\n",
       "      <td>41.932832</td>\n",
       "      <td>2015-12-29 14:25:22.594000000</td>\n",
       "      <td>36.929549</td>\n",
       "      <td>2015-12-28 01:29:55.901000000</td>\n",
       "      <td>33.236594</td>\n",
       "      <td>2015-12-29 14:46:06.628000000</td>\n",
       "      <td>33.236594</td>\n",
       "      <td>2016-01-05 01:06:59.546000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             student_id  assignment1_grade  \\\n",
       "0  B73F2C11-70F0-E37D-8B10-1D20AFED50B1          92.733946   \n",
       "1  98A0FAE0-A19A-13D2-4BB5-CFBFD94031D1          86.790821   \n",
       "2  D0F62040-CEB0-904C-F563-2F8620916C4E          85.512541   \n",
       "3  FFDF2B2C-F514-EF7F-6538-A6A53518E9DC          86.030665   \n",
       "4  5ECBEEB6-F1CE-80AE-3164-E45E99473FB4          64.813800   \n",
       "\n",
       "          assignment1_submission  assignment2_grade  \\\n",
       "0  2015-11-02 06:55:34.282000000          83.030552   \n",
       "1  2015-11-29 14:57:44.429000000          86.290821   \n",
       "2  2016-01-09 05:36:02.389000000          85.512541   \n",
       "3  2016-04-30 06:50:39.801000000          68.824532   \n",
       "4  2015-12-13 17:06:10.750000000          51.491040   \n",
       "\n",
       "          assignment2_submission  assignment3_grade  \\\n",
       "0  2015-11-09 02:22:58.938000000          67.164441   \n",
       "1  2015-12-06 17:41:18.449000000          69.772657   \n",
       "2  2016-01-09 06:39:44.416000000          68.410033   \n",
       "3  2016-04-30 17:20:38.727000000          61.942079   \n",
       "4  2015-12-14 12:25:12.056000000          41.932832   \n",
       "\n",
       "          assignment3_submission  assignment4_grade  \\\n",
       "0  2015-11-12 08:58:33.998000000          53.011553   \n",
       "1  2015-12-10 08:54:55.904000000          55.098125   \n",
       "2  2016-01-15 20:22:45.882000000          54.728026   \n",
       "3  2016-05-12 07:47:16.326000000          49.553663   \n",
       "4  2015-12-29 14:25:22.594000000          36.929549   \n",
       "\n",
       "          assignment4_submission  assignment5_grade  \\\n",
       "0  2015-11-16 01:21:24.663000000          47.710398   \n",
       "1  2015-12-13 17:32:30.941000000          49.588313   \n",
       "2  2016-01-11 12:41:50.749000000          49.255224   \n",
       "3  2016-05-07 16:09:20.485000000          49.553663   \n",
       "4  2015-12-28 01:29:55.901000000          33.236594   \n",
       "\n",
       "          assignment5_submission  assignment6_grade  \\\n",
       "0  2015-11-20 13:24:59.692000000          38.168318   \n",
       "1  2015-12-19 23:26:39.285000000          44.629482   \n",
       "2  2016-01-11 17:31:12.489000000          44.329701   \n",
       "3  2016-05-24 12:51:18.016000000          44.598297   \n",
       "4  2015-12-29 14:46:06.628000000          33.236594   \n",
       "\n",
       "          assignment6_submission  \n",
       "0  2015-11-22 18:31:15.934000000  \n",
       "1  2015-12-21 17:07:24.275000000  \n",
       "2  2016-01-17 16:24:42.765000000  \n",
       "3  2016-05-26 08:09:12.058000000  \n",
       "4  2016-01-05 01:06:59.546000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/grades.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25f074f1-66db-490c-abb6-75b78517ae67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2315 rows and 13 columns\n"
     ]
    }
   ],
   "source": [
    "#If we take a look the data frame inside, we see have six different assignments\n",
    "print(\"There are {} rows and {} columns\".format(df.shape[0], df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af212340-b468-4bc5-bc68-043e6e39eff2",
   "metadata": {},
   "source": [
    "For purpose of this lecture, Let's segment this population into two pieces. Let's say those finis the fist assignment by the end of December 2015, we'll call them early finishers, and those who finish ir sometime after that, we'll call them late finishers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b31719-902f-49f9-b325-8b85a87721af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>assignment1_grade</th>\n",
       "      <th>assignment1_submission</th>\n",
       "      <th>assignment2_grade</th>\n",
       "      <th>assignment2_submission</th>\n",
       "      <th>assignment3_grade</th>\n",
       "      <th>assignment3_submission</th>\n",
       "      <th>assignment4_grade</th>\n",
       "      <th>assignment4_submission</th>\n",
       "      <th>assignment5_grade</th>\n",
       "      <th>assignment5_submission</th>\n",
       "      <th>assignment6_grade</th>\n",
       "      <th>assignment6_submission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D0F62040-CEB0-904C-F563-2F8620916C4E</td>\n",
       "      <td>85.512541</td>\n",
       "      <td>2016-01-09 05:36:02.389000000</td>\n",
       "      <td>85.512541</td>\n",
       "      <td>2016-01-09 06:39:44.416000000</td>\n",
       "      <td>68.410033</td>\n",
       "      <td>2016-01-15 20:22:45.882000000</td>\n",
       "      <td>54.728026</td>\n",
       "      <td>2016-01-11 12:41:50.749000000</td>\n",
       "      <td>49.255224</td>\n",
       "      <td>2016-01-11 17:31:12.489000000</td>\n",
       "      <td>44.329701</td>\n",
       "      <td>2016-01-17 16:24:42.765000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FFDF2B2C-F514-EF7F-6538-A6A53518E9DC</td>\n",
       "      <td>86.030665</td>\n",
       "      <td>2016-04-30 06:50:39.801000000</td>\n",
       "      <td>68.824532</td>\n",
       "      <td>2016-04-30 17:20:38.727000000</td>\n",
       "      <td>61.942079</td>\n",
       "      <td>2016-05-12 07:47:16.326000000</td>\n",
       "      <td>49.553663</td>\n",
       "      <td>2016-05-07 16:09:20.485000000</td>\n",
       "      <td>49.553663</td>\n",
       "      <td>2016-05-24 12:51:18.016000000</td>\n",
       "      <td>44.598297</td>\n",
       "      <td>2016-05-26 08:09:12.058000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3217BE3F-E4B0-C3B6-9F64-462456819CE4</td>\n",
       "      <td>87.498744</td>\n",
       "      <td>2016-03-05 11:05:25.408000000</td>\n",
       "      <td>69.998995</td>\n",
       "      <td>2016-03-09 07:29:52.405000000</td>\n",
       "      <td>55.999196</td>\n",
       "      <td>2016-03-16 22:31:24.316000000</td>\n",
       "      <td>50.399276</td>\n",
       "      <td>2016-03-18 07:19:26.032000000</td>\n",
       "      <td>45.359349</td>\n",
       "      <td>2016-03-19 10:35:41.869000000</td>\n",
       "      <td>45.359349</td>\n",
       "      <td>2016-03-23 14:02:00.987000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F1CB5AA1-B3DE-5460-FAFF-BE951FD38B5F</td>\n",
       "      <td>80.576090</td>\n",
       "      <td>2016-01-24 18:24:25.619000000</td>\n",
       "      <td>72.518481</td>\n",
       "      <td>2016-01-27 13:37:12.943000000</td>\n",
       "      <td>65.266633</td>\n",
       "      <td>2016-01-30 14:34:36.581000000</td>\n",
       "      <td>65.266633</td>\n",
       "      <td>2016-02-03 22:08:49.002000000</td>\n",
       "      <td>65.266633</td>\n",
       "      <td>2016-02-16 14:22:23.664000000</td>\n",
       "      <td>65.266633</td>\n",
       "      <td>2016-02-18 08:35:04.796000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E2C617C2-4654-622C-AB50-1550C4BE42A0</td>\n",
       "      <td>59.270882</td>\n",
       "      <td>2016-03-06 12:06:26.185000000</td>\n",
       "      <td>59.270882</td>\n",
       "      <td>2016-03-13 02:07:25.289000000</td>\n",
       "      <td>53.343794</td>\n",
       "      <td>2016-03-17 07:30:09.241000000</td>\n",
       "      <td>53.343794</td>\n",
       "      <td>2016-03-20 21:45:56.229000000</td>\n",
       "      <td>42.675035</td>\n",
       "      <td>2016-03-27 15:55:04.414000000</td>\n",
       "      <td>38.407532</td>\n",
       "      <td>2016-03-30 20:33:13.554000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             student_id  assignment1_grade  \\\n",
       "2  D0F62040-CEB0-904C-F563-2F8620916C4E          85.512541   \n",
       "3  FFDF2B2C-F514-EF7F-6538-A6A53518E9DC          86.030665   \n",
       "6  3217BE3F-E4B0-C3B6-9F64-462456819CE4          87.498744   \n",
       "7  F1CB5AA1-B3DE-5460-FAFF-BE951FD38B5F          80.576090   \n",
       "9  E2C617C2-4654-622C-AB50-1550C4BE42A0          59.270882   \n",
       "\n",
       "          assignment1_submission  assignment2_grade  \\\n",
       "2  2016-01-09 05:36:02.389000000          85.512541   \n",
       "3  2016-04-30 06:50:39.801000000          68.824532   \n",
       "6  2016-03-05 11:05:25.408000000          69.998995   \n",
       "7  2016-01-24 18:24:25.619000000          72.518481   \n",
       "9  2016-03-06 12:06:26.185000000          59.270882   \n",
       "\n",
       "          assignment2_submission  assignment3_grade  \\\n",
       "2  2016-01-09 06:39:44.416000000          68.410033   \n",
       "3  2016-04-30 17:20:38.727000000          61.942079   \n",
       "6  2016-03-09 07:29:52.405000000          55.999196   \n",
       "7  2016-01-27 13:37:12.943000000          65.266633   \n",
       "9  2016-03-13 02:07:25.289000000          53.343794   \n",
       "\n",
       "          assignment3_submission  assignment4_grade  \\\n",
       "2  2016-01-15 20:22:45.882000000          54.728026   \n",
       "3  2016-05-12 07:47:16.326000000          49.553663   \n",
       "6  2016-03-16 22:31:24.316000000          50.399276   \n",
       "7  2016-01-30 14:34:36.581000000          65.266633   \n",
       "9  2016-03-17 07:30:09.241000000          53.343794   \n",
       "\n",
       "          assignment4_submission  assignment5_grade  \\\n",
       "2  2016-01-11 12:41:50.749000000          49.255224   \n",
       "3  2016-05-07 16:09:20.485000000          49.553663   \n",
       "6  2016-03-18 07:19:26.032000000          45.359349   \n",
       "7  2016-02-03 22:08:49.002000000          65.266633   \n",
       "9  2016-03-20 21:45:56.229000000          42.675035   \n",
       "\n",
       "          assignment5_submission  assignment6_grade  \\\n",
       "2  2016-01-11 17:31:12.489000000          44.329701   \n",
       "3  2016-05-24 12:51:18.016000000          44.598297   \n",
       "6  2016-03-19 10:35:41.869000000          45.359349   \n",
       "7  2016-02-16 14:22:23.664000000          65.266633   \n",
       "9  2016-03-27 15:55:04.414000000          38.407532   \n",
       "\n",
       "          assignment6_submission  \n",
       "2  2016-01-17 16:24:42.765000000  \n",
       "3  2016-05-26 08:09:12.058000000  \n",
       "6  2016-03-23 14:02:00.987000000  \n",
       "7  2016-02-18 08:35:04.796000000  \n",
       "9  2016-03-30 20:33:13.554000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_finishers = df[pd.to_datetime(df['assignment1_submission']) < '2016']\n",
    "early_finishers.head()\n",
    "late_finishers = df[~df.index.isin(early_finishers.index)]\n",
    "late_finishers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218865a-1104-4bc7-a5df-e3e11ef8d801",
   "metadata": {},
   "source": [
    "There are a lotsof other ways to do this. For intance, you could just copy and paste the fisrt projection and change the signd from less than o greater tha or equal to. This is ok, but if you decide you want to change the date down the road you have to remember to change it in two places. You could also do a joi nof the dataframe df with early_finishers - if do you a lest join you only keep items in the left dataframe, so this would have been a old answer. You also could have written a function that determines if someone is early or late, and the called. apply() on the dataframe and added a new column to the dataframe. This is a pretty reasonable answer as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d34aa4c-6114-4d43-9778-213beead6023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.94728457024304\n",
      "74.0450648477065\n"
     ]
    }
   ],
   "source": [
    "# As you've seen, the pandas data frame object has a variety of statistical function associated with it. If we call the mean function directly on the data frame, we see that each of the means \n",
    "# for the assignments are aclculated. Let's compare the means for our two populations\n",
    "print(early_finishers['assignment1_grade'].mean())\n",
    "print(late_finishers['assignment1_grade'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3749c86-21fd-4448-935e-dcb9912eb0c0",
   "metadata": {},
   "source": [
    "Ok, these look prety similar. But, are they the same? What do we mean by similar? This is where the students' t-test comes in. It allows us to form the alternative hypothesis (\"These are different\") as well as the null hypothesis (\"These are the same\") and then test that null hypothesis. When doing hypothesis testing, we have to choose a significance level as a threshold for how much of a chance we're willing to accept. This significance level is typically called alpha. For this example, Let's use a threshold of 0.05 for our alpha or 5%. Now this is a commonly used number but it's really quite arbitrary.\n",
    "The SciPy library contains a number of different statistical tests and forms a basis for hypothesis testing in Python and we're going to use the ttest_ind() function which does an independent t-test (meaning the populations are not relaed to one another). The result of ttest_index() are the t-statistic and a p-value. It's this latter value, the probability, which is most important to us, as it indicates the chance (between 0 and 1) of our null hypothesis being True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bf1ce1e-df29-4e8b-8efc-67f5930462d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.3223540853721596, pvalue=0.18618101101713855)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "ttest_ind(early_finishers['assignment1_grade'], late_finishers['assignment1_grade'])\n",
    "# So here we see that the probability is 0.18, and this is above our alpha value of 0.05. This means that we cannot reject the null hypothesis. The null hypothesis was that the two populations\n",
    "# are the same, and we don't have enough certainty in our evidence (because it is greater tha alpha) to come to a conclusion to the contrary. This doesn't mean that we have proven the populations\n",
    "# are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29c64a73-c559-4739-8030-450629680954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=1.2514717608216366, pvalue=0.2108889627004424)\n",
      "Ttest_indResult(statistic=1.6133726558705392, pvalue=0.10679998102227865)\n",
      "Ttest_indResult(statistic=0.049671157386456125, pvalue=0.960388729789337)\n",
      "Ttest_indResult(statistic=-0.05279315545404755, pvalue=0.9579012739746492)\n",
      "Ttest_indResult(statistic=-0.11609743352612056, pvalue=0.9075854011989656)\n"
     ]
    }
   ],
   "source": [
    "# Why don't we check the other assignment grades?\n",
    "print(ttest_ind(early_finishers['assignment2_grade'], late_finishers['assignment2_grade']))\n",
    "print(ttest_ind(early_finishers['assignment3_grade'], late_finishers['assignment3_grade']))\n",
    "print(ttest_ind(early_finishers['assignment4_grade'], late_finishers['assignment4_grade']))\n",
    "print(ttest_ind(early_finishers['assignment5_grade'], late_finishers['assignment5_grade']))\n",
    "print(ttest_ind(early_finishers['assignment6_grade'], late_finishers['assignment6_grade']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d8be3a-508d-41b8-8be0-8c12cdee9279",
   "metadata": {},
   "source": [
    "Ok, so it looks like in this data we do not have enough evidence to suggest the populations differ with respect to grade. Let's take a look those p-values for a moment though, because they are saying things that can inform experimental design down the road. For instance, one of the assignments, assignment 3, has a p-value around 0.1. This means that if we accepted a level of chance similarity of 11% this would have been considered statistically significant. As a research, this would suggest to me that there is somenthing here worth considering following up on. For instance, if we had a small number of participants (we don't) or if there was something unique about this assignment as it relates to our experiment (whatever it was) then there may be followup experiments we could run.\n",
    "P-values have come under fire recently for being induficient for telling us enough about the interactions which are happening, and two other techniques, confidence intervalues and bayesian analyses, are being used more regularly. One issue with p-values is that as you run more tests are likely to get a value which is statistically significant just by chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8abb2c58-2955-4525-abb6-31b8a13cb951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.906527</td>\n",
       "      <td>0.122048</td>\n",
       "      <td>0.667143</td>\n",
       "      <td>0.498016</td>\n",
       "      <td>0.699089</td>\n",
       "      <td>0.386407</td>\n",
       "      <td>0.205689</td>\n",
       "      <td>0.356401</td>\n",
       "      <td>0.906706</td>\n",
       "      <td>0.870242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567573</td>\n",
       "      <td>0.422556</td>\n",
       "      <td>0.910511</td>\n",
       "      <td>0.376145</td>\n",
       "      <td>0.785454</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.312443</td>\n",
       "      <td>0.608675</td>\n",
       "      <td>0.807268</td>\n",
       "      <td>0.975747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.369832</td>\n",
       "      <td>0.493761</td>\n",
       "      <td>0.308976</td>\n",
       "      <td>0.716444</td>\n",
       "      <td>0.059590</td>\n",
       "      <td>0.026350</td>\n",
       "      <td>0.381108</td>\n",
       "      <td>0.060707</td>\n",
       "      <td>0.703992</td>\n",
       "      <td>0.640314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394702</td>\n",
       "      <td>0.125042</td>\n",
       "      <td>0.149529</td>\n",
       "      <td>0.436992</td>\n",
       "      <td>0.941209</td>\n",
       "      <td>0.413437</td>\n",
       "      <td>0.727757</td>\n",
       "      <td>0.119147</td>\n",
       "      <td>0.497130</td>\n",
       "      <td>0.853357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.992802</td>\n",
       "      <td>0.170454</td>\n",
       "      <td>0.679962</td>\n",
       "      <td>0.768920</td>\n",
       "      <td>0.134241</td>\n",
       "      <td>0.784590</td>\n",
       "      <td>0.186404</td>\n",
       "      <td>0.147237</td>\n",
       "      <td>0.697916</td>\n",
       "      <td>0.108090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521540</td>\n",
       "      <td>0.955655</td>\n",
       "      <td>0.151910</td>\n",
       "      <td>0.202401</td>\n",
       "      <td>0.137684</td>\n",
       "      <td>0.583242</td>\n",
       "      <td>0.288515</td>\n",
       "      <td>0.152871</td>\n",
       "      <td>0.020032</td>\n",
       "      <td>0.773015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.512483</td>\n",
       "      <td>0.976235</td>\n",
       "      <td>0.523540</td>\n",
       "      <td>0.846988</td>\n",
       "      <td>0.806182</td>\n",
       "      <td>0.799384</td>\n",
       "      <td>0.053837</td>\n",
       "      <td>0.850632</td>\n",
       "      <td>0.639410</td>\n",
       "      <td>0.463102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507921</td>\n",
       "      <td>0.527972</td>\n",
       "      <td>0.951124</td>\n",
       "      <td>0.065320</td>\n",
       "      <td>0.347305</td>\n",
       "      <td>0.925234</td>\n",
       "      <td>0.749949</td>\n",
       "      <td>0.810437</td>\n",
       "      <td>0.549980</td>\n",
       "      <td>0.585343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.421669</td>\n",
       "      <td>0.022637</td>\n",
       "      <td>0.806027</td>\n",
       "      <td>0.687236</td>\n",
       "      <td>0.311395</td>\n",
       "      <td>0.235594</td>\n",
       "      <td>0.506871</td>\n",
       "      <td>0.556030</td>\n",
       "      <td>0.069906</td>\n",
       "      <td>0.154972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316966</td>\n",
       "      <td>0.176643</td>\n",
       "      <td>0.152680</td>\n",
       "      <td>0.896096</td>\n",
       "      <td>0.447172</td>\n",
       "      <td>0.853328</td>\n",
       "      <td>0.686754</td>\n",
       "      <td>0.593648</td>\n",
       "      <td>0.312059</td>\n",
       "      <td>0.012488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.906527  0.122048  0.667143  0.498016  0.699089  0.386407  0.205689   \n",
       "1  0.369832  0.493761  0.308976  0.716444  0.059590  0.026350  0.381108   \n",
       "2  0.992802  0.170454  0.679962  0.768920  0.134241  0.784590  0.186404   \n",
       "3  0.512483  0.976235  0.523540  0.846988  0.806182  0.799384  0.053837   \n",
       "4  0.421669  0.022637  0.806027  0.687236  0.311395  0.235594  0.506871   \n",
       "\n",
       "         7         8         9   ...        90        91        92        93  \\\n",
       "0  0.356401  0.906706  0.870242  ...  0.567573  0.422556  0.910511  0.376145   \n",
       "1  0.060707  0.703992  0.640314  ...  0.394702  0.125042  0.149529  0.436992   \n",
       "2  0.147237  0.697916  0.108090  ...  0.521540  0.955655  0.151910  0.202401   \n",
       "3  0.850632  0.639410  0.463102  ...  0.507921  0.527972  0.951124  0.065320   \n",
       "4  0.556030  0.069906  0.154972  ...  0.316966  0.176643  0.152680  0.896096   \n",
       "\n",
       "         94        95        96        97        98        99  \n",
       "0  0.785454  0.002866  0.312443  0.608675  0.807268  0.975747  \n",
       "1  0.941209  0.413437  0.727757  0.119147  0.497130  0.853357  \n",
       "2  0.137684  0.583242  0.288515  0.152871  0.020032  0.773015  \n",
       "3  0.347305  0.925234  0.749949  0.810437  0.549980  0.585343  \n",
       "4  0.447172  0.853328  0.686754  0.593648  0.312059  0.012488  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame([np.random.random(100) for x in range(100)])\n",
    "# Pause this and reflect -- do you understand the list pomprehension and how I created this DataFrame? You don't have to use a list comprehension to do this, but you should be able to read this\n",
    "# and figure out how it works as this a commonly used approach on web forums.\n",
    "df2 = pd.DataFrame([np.random.random(100) for x in range(100)])\n",
    "df1.head()\n",
    "# Are these two DataFrames the same? Maybe a better question is, for a given row inside of df1, is it the same as the row inside df2?. Let's take a look. Let's say our critical value is 0.1\n",
    "# or and alpha of 10%. And we're going to compare each column in df1 to the same numbered column in df2. And we'll report when the p-value isn't less than 10% which means that we have sufficient\n",
    "# evidence to say that the columns are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b094df9-4f0f-4b19-a45f-cca5c7d73ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col 6 is stadistically significantly different at alpha = 0.1, pval = 0.05337930970728126\n",
      "Col 9 is stadistically significantly different at alpha = 0.1, pval = 0.014493883127167092\n",
      "Col 21 is stadistically significantly different at alpha = 0.1, pval = 0.08684051920560812\n",
      "Col 28 is stadistically significantly different at alpha = 0.1, pval = 0.0010143415081508669\n",
      "Col 29 is stadistically significantly different at alpha = 0.1, pval = 0.07754102377783406\n",
      "Col 52 is stadistically significantly different at alpha = 0.1, pval = 0.0632418084059522\n",
      "Col 62 is stadistically significantly different at alpha = 0.1, pval = 0.06194914868615695\n",
      "Col 75 is stadistically significantly different at alpha = 0.1, pval = 0.09382263500873238\n",
      "Col 81 is stadistically significantly different at alpha = 0.1, pval = 0.03770836837891057\n",
      "Total number different was 9, which is 9.0%\n",
      "Col 9 is stadistically significantly different at alpha = 0.05, pval = 0.014493883127167092\n",
      "Col 28 is stadistically significantly different at alpha = 0.05, pval = 0.0010143415081508669\n",
      "Col 81 is stadistically significantly different at alpha = 0.05, pval = 0.03770836837891057\n",
      "Total number different was 3, which is 3.0%\n"
     ]
    }
   ],
   "source": [
    "def test_columns(alpha=0.1):\n",
    "    num_diff = 0\n",
    "    for col in df1.columns:\n",
    "        teststat, pval = ttest_ind(df1[col], df2[col])\n",
    "        if pval <= alpha:\n",
    "            print(\"Col {} is stadistically significantly different at alpha = {}, pval = {}\". format(col, alpha, pval))\n",
    "            num_diff = num_diff + 1\n",
    "    print(\"Total number different was {}, which is {}%\".format(num_diff, float(num_diff)/len(df1.columns)*100))\n",
    "\n",
    "test_columns()\n",
    "# Interesting, so we see that there are a bunch of columns that are different! IN fact, that number looks a lot like the alpha value we chose. So what's going on - shouldn't all of the columns be\n",
    "# the same? Remember that all the ttest does is check if two sets are similar given some level of confidence, in our case, 10%. The more random comparisons you do, the more will just happen to be\n",
    "# the same by chance. In this example, we checked 100 columns, so we would expect there to be roughly 10 of them if our alpha was 0.1.\n",
    "test_columns(0.05)\n",
    "# So, keep this in mind when yu are doing statistical tests like the t-test which has a p-value. Understand that this p-value isn't magic, that it's a threshold for you when reporting results\n",
    "# and trying to answer your hypothesis. Whta's a reasonalbe threshold? Depends on your question, and you need to engage domain experts to better understand what they would consider significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e1fd5b-a7a0-4624-9ea9-760891f7e1ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
